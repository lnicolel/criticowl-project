{"ast":null,"code":"//     wink-tokenizer\n//     Multilingual tokenizer that automatically tags each token with its type.\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-tokenizer”.\n//\n//     Permission is hereby granted, free of charge, to any person obtaining a\n//     copy of this software and associated documentation files (the \"Software\"),\n//     to deal in the Software without restriction, including without limitation\n//     the rights to use, copy, modify, merge, publish, distribute, sublicense,\n//     and/or sell copies of the Software, and to permit persons to whom the\n//     Software is furnished to do so, subject to the following conditions:\n//\n//     The above copyright notice and this permission notice shall be included\n//     in all copies or substantial portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\nvar emojiRegex = require('emoji-regex');\nvar contractions = require('./eng-contractions.js');\nvar rgxSpaces = /\\s+/g;\n// Ordinals only for Latin like 1st, 2nd or 12th or 33rd.\nvar rgxOrdinalL1 = /1\\dth|[04-9]th|1st|2nd|3rd|[02-9]1st|[02-9]2nd|[02-9]3rd|[02-9][04-9]th|\\d+\\d[04-9]th|\\d+\\d1st|\\d+\\d2nd|\\d+\\d3rd/g;\n// Apart from detecting pure integers or decimals, also detect numbers containing\n// `. - / ,` so that dates, ip address, fractions and things like codes or part\n// numbers are also detected as numbers only. These regex will therefore detected\n// 8.8.8.8 or 12-12-1924 or 1,1,1,1.00 or 1/4 or 1/4/66/777 as numbers.\n// Latin-1 Numbers.\nvar rgxNumberL1 = /\\d+\\/\\d+|\\d(?:[\\.,-\\/]?\\d)*(?:\\.\\d+)?/g;\n// Devanagari Numbers.\nvar rgxNumberDV = /[\\u0966-\\u096F]+\\/[\\u0966-\\u096F]+|[\\u0966-\\u096F](?:[\\.,-\\/]?[\\u0966-\\u096F])*(?:\\.[\\u0966-\\u096F]+)?/g;\nvar rgxMention = /@\\w+/g;\n// Latin-1 Hashtags.\n// Include entire Latin-1 script and not just English alphas.\nvar rgxHashtagL1 = /#[a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF_][a-z0-9\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF_]*/gi;\n// Devanagari Hashtags\nvar rgxHashtagDV = /#[\\u0900-\\u0963\\u0970-\\u097F_][\\u0900-\\u0963\\u0970-\\u097F\\u0966-\\u096F0-9_]*/gi;\n// EMail is EN character set.\nvar rgxEmail = /[-!#$%&'*+\\/=?^\\w{|}~](?:\\.?[-!#$%&'*+\\/=?^\\w`{|}~])*@[a-z0-9](?:-?\\.?[a-z0-9])*(?:\\.[a-z](?:-?[a-z0-9])*)+/gi;\n// Bitcoin, Ruble, Indian Rupee, Other Rupee, Dollar, Pound, Yen, Euro, Wong.\nvar rgxCurrency = /[₿₽₹₨$£¥€₩]/g;\n// These include both the punctuations: Latin-1 & Devanagari.\nvar rgxPunctuation = /[’'‘’`“”\"\\[\\]\\(\\){}…,\\.!;\\?\\-:\\u0964\\u0965]/g;\nvar rgxQuotedPhrase = /\"[^\"]*\"/g;\n// NOTE: URL will support only EN character set for now.\nvar rgxURL = /(?:https?:\\/\\/)(?:[\\da-z\\.-]+)\\.(?:[a-z\\.]{2,6})(?:[\\/\\w\\.\\-\\?#=]*)*\\/?/gi;\nvar rgxEmoji = emojiRegex();\nvar rgxEmoticon = /:-?[dps\\*\\/\\[\\]{}\\(\\)]|;-?[/(/)d]|<3/gi;\nvar rgxTime = /(?:\\d|[01]\\d|2[0-3]):?(?:[0-5][0-9])?\\s?(?:[ap]\\.?m\\.?|hours|hrs)/gi;\n// Inlcude [Latin-1 Supplement Unicode Block](https://en.wikipedia.org/wiki/Latin-1_Supplement_(Unicode_block))\nvar rgxWordL1 = /[a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF][a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF']*/gi;\n// Define [Devanagari Unicode Block](https://unicode.org/charts/PDF/U0900.pdf)\nvar rgxWordDV = /[\\u0900-\\u094F\\u0951-\\u0963\\u0970-\\u097F]+/gi;\n// Symbols go here; including Om.\nvar rgxSymbol = /[\\u0950~@#%\\^\\+=\\*\\|\\/<>&]/g;\n// For detecting if the word is a potential contraction.\nvar rgxContraction = /'/;\n// Singular & Plural possessive\nvar rgxPosSingular = /([a-z]+)('s)$/i;\nvar rgxPosPlural = /([a-z]+s)(')$/i;\n// Regexes and their categories; used for tokenizing via match/split. The\n// sequence is *critical* for correct tokenization.\nvar rgxsMaster = [{\n  regex: rgxQuotedPhrase,\n  category: 'quoted_phrase'\n}, {\n  regex: rgxURL,\n  category: 'url'\n}, {\n  regex: rgxEmail,\n  category: 'email'\n}, {\n  regex: rgxMention,\n  category: 'mention'\n}, {\n  regex: rgxHashtagL1,\n  category: 'hashtag'\n}, {\n  regex: rgxHashtagDV,\n  category: 'hashtag'\n}, {\n  regex: rgxEmoji,\n  category: 'emoji'\n}, {\n  regex: rgxEmoticon,\n  category: 'emoticon'\n}, {\n  regex: rgxTime,\n  category: 'time'\n}, {\n  regex: rgxOrdinalL1,\n  category: 'ordinal'\n}, {\n  regex: rgxNumberL1,\n  category: 'number'\n}, {\n  regex: rgxNumberDV,\n  category: 'number'\n}, {\n  regex: rgxCurrency,\n  category: 'currency'\n}, {\n  regex: rgxWordL1,\n  category: 'word'\n}, {\n  regex: rgxWordDV,\n  category: 'word'\n}, {\n  regex: rgxPunctuation,\n  category: 'punctuation'\n}, {\n  regex: rgxSymbol,\n  category: 'symbol'\n}];\n\n// Used to generate finger print from the tokens.\n// NOTE: this variable is being reset in `defineConfig()`.\nvar fingerPrintCodes = {\n  emoticon: 'c',\n  email: 'e',\n  emoji: 'j',\n  hashtag: 'h',\n  mention: 'm',\n  number: 'n',\n  ordinal: 'o',\n  quoted_phrase: 'q',\n  // eslint-disable-line camelcase\n  currency: 'r',\n  // symbol: 's',\n  time: 't',\n  url: 'u',\n  word: 'w',\n  alien: 'z'\n};\n\n// ### tokenizer\n/**\n *\n * Creates an instance of {@link Tokenizer}.\n *\n * @return {Tokenizer} object conatining set of API methods for tokenizing a sentence\n * and defining configuration, plugin etc.\n * @example\n * // Load wink tokenizer.\n * var tokenizer = require( 'wink-tokenizer' );\n * // Create your instance of wink tokenizer.\n * var myTokenizer = tokenizer();\n*/\nvar tokenizer = function () {\n  // Default configuration: most comprehensive tokenization. Make deep copy!\n  var rgxs = rgxsMaster.slice(0);\n  // The result of last call to `tokenize()` is retained here.\n  var finalTokens = [];\n  // Returned!\n\n  /**\n   * @classdesc Tokenizer class\n   * @class Tokenizer\n   * @hideconstructor\n   */\n  var methods = Object.create(null);\n\n  // ### manageContraction\n  /**\n   *\n   * Splits a contractions into words by first trying a lookup in strandard\n   * `contractions`; if the lookup fails, it checks for possessive in `'s` or\n   * `s'` forms and separates the possesive part from the word. Otherwise the\n   * contraction is treated as a normal word and no splitting occurs.\n   *\n   * @param {string} word that could be a potential conraction.\n   * @param {object[]} tokens where the outcome is pushed.\n   * @return {object[]} updated tokens according to the `word.`\n   * @private\n  */\n  var manageContraction = function (word, tokens) {\n    var ct = contractions[word];\n    var matches;\n    if (ct === undefined) {\n      // Try possesive of sigular & plural forms\n      matches = word.match(rgxPosSingular);\n      if (matches) {\n        tokens.push({\n          value: matches[1],\n          tag: 'word'\n        });\n        tokens.push({\n          value: matches[2],\n          tag: 'word'\n        });\n      } else {\n        matches = word.match(rgxPosPlural);\n        if (matches) {\n          tokens.push({\n            value: matches[1],\n            tag: 'word'\n          });\n          tokens.push({\n            value: matches[2],\n            tag: 'word'\n          });\n        } else tokens.push({\n          value: word,\n          tag: 'word'\n        });\n      }\n    } else {\n      // Manage via lookup; ensure cloning!\n      tokens.push(Object.assign({}, ct[0]));\n      tokens.push(Object.assign({}, ct[1]));\n      if (ct[2]) tokens.push(Object.assign({}, ct[2]));\n    }\n    return tokens;\n  }; // manageContraction()\n\n  // ### tokenizeTextUnit\n  /**\n   *\n   * Attempts to tokenize the input `text` using the `rgxSplit`. The tokenization\n   * is carried out by combining the regex matches and splits in the right sequence.\n   * The matches are the *real tokens*, whereas splits are text units that are\n   * tokenized in later rounds! The real tokens (i.e. matches) are pushed as\n   * `object` and splits as `string`.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} rgxSplit object containing the regex and it's category.\n   * @return {array} of tokens.\n   * @private\n  */\n  var tokenizeTextUnit = function (text, rgxSplit) {\n    // Regex matches go here; note each match is a token and has the same tag\n    // as of regex's category.\n    var matches = text.match(rgxSplit.regex);\n    // Balance is \"what needs to be tokenized\".\n    var balance = text.split(rgxSplit.regex);\n    // The result, in form of combination of tokens & matches, is captured here.\n    var tokens = [];\n    // The tag;\n    var tag = rgxSplit.category;\n    // Helper variables.\n    var aword,\n      i,\n      imax,\n      k = 0,\n      t;\n\n    // Combine tokens & matches in the following pattern [ b0 m0 b1 m1 ... ]\n    matches = matches ? matches : [];\n    for (i = 0, imax = balance.length; i < imax; i += 1) {\n      t = balance[i];\n      t = t.trim();\n      if (t) tokens.push(t);\n      if (k < matches.length) {\n        if (tag === 'word') {\n          // Tag type `word` token may have a contraction.\n          aword = matches[k];\n          if (rgxContraction.test(aword)) {\n            tokens = manageContraction(aword, tokens);\n          } else {\n            // Means there is no contraction.\n            tokens.push({\n              value: aword,\n              tag: tag\n            });\n          }\n        } else tokens.push({\n          value: matches[k],\n          tag: tag\n        });\n      }\n      k += 1;\n    }\n    return tokens;\n  }; // tokenizeTextUnit()\n\n  // ### tokenizeTextRecursively\n  /**\n   *\n   * Tokenizes the input text recursively using the array of `regexes` and then\n   * the `tokenizeTextUnit()` function. If (or whenever) the `regexes` becomes\n   * empty, it simply splits the text on non-word characters instead of using\n   * the `tokenizeTextUnit()` function.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} regexes object containing the regex and it's category.\n   * @return {undefined} nothing!\n   * @private\n  */\n  var tokenizeTextRecursively = function (text, regexes) {\n    var sentence = text.trim();\n    var tokens = [];\n    var i, imax;\n    if (!regexes.length) {\n      // No regex left, split on `spaces` and tag every token as **alien**.\n      text.split(rgxSpaces).forEach(function (tkn) {\n        finalTokens.push({\n          value: tkn.trim(),\n          tag: 'alien'\n        });\n      });\n      return;\n    }\n    var rgx = regexes[0];\n    tokens = tokenizeTextUnit(sentence, rgx);\n    for (i = 0, imax = tokens.length; i < imax; i += 1) {\n      if (typeof tokens[i] === 'string') {\n        // Strings become candidates for further tokenization.\n        tokenizeTextRecursively(tokens[i], regexes.slice(1));\n      } else {\n        finalTokens.push(tokens[i]);\n      }\n    }\n  }; // tokenizeTextRecursively()\n\n  // ### defineConfig\n  /**\n   *\n   * Defines the configuration in terms of the types of token that will be\n   * extracted by [`tokenize()`](#tokenize) method. Note by default, all types\n   * of tokens will be detected and tagged automatically.\n   *\n   * @method Tokenizer#defineConfig\n   * @param {object} config It defines 0 or more properties from the list of\n   * **14** properties. A true value for a property ensures tokenization\n   * for that type of text; whereas false value will mean that the tokenization of that\n   * type of text will not be attempted. It also **resets** the effect of any previous\n   * call(s) to the [`addRegex()`](#addregex) API.\n   *\n   * *An empty config object is equivalent to splitting on spaces. Whatever tokens\n   * are created like this are tagged as **alien** and **`z`** is the\n   * [finger print](#gettokensfp) code of this token type.*\n   *\n   * The table below gives the name of each property and it's description including\n   * examples. The character with in paranthesis is the [finger print](#gettokensfp) code for the\n   * token of that type.\n   * @param {boolean} [config.currency=true] such as **$** or **£** symbols (**`r`**)\n   * @param {boolean} [config.email=true] for example **john@acme.com** or **superman1@gmail.com** (**`e`**)\n   * @param {boolean} [config.emoji=true] any standard unicode emojis e.g. 😊 or 😂 or 🎉 (**`j`**)\n   * @param {boolean} [config.emoticon=true] common emoticons such as **`:-)`** or **`:D`** (**`c`**)\n   * @param {boolean} [config.hashtag=true] hash tags such as **`#happy`** or **`#followme`** (**`h`**)\n   * @param {boolean} [config.number=true] any integer, decimal number, fractions such as **19**, **2.718**\n   * or **1/4** and numerals containing \"**`, - / .`**\", for example 12-12-1924 (**`n`**)\n   * @param {boolean} [config.ordinal=true] ordinals like **1st**, **2nd**, **3rd**, **4th** or **12th** or **91st** (**`o`**)\n   * @param {boolean} [config.punctuation=true] common punctuation such as **`?`** or **`,`**\n   * ( token becomes fingerprint )\n   * @param {boolean} [config.quoted_phrase=false] any **\"quoted text\"** in the sentence. _Note: its default value is **false**._ (**`q`**)\n   * @param {boolean} [config.symbol=true] for example **`~`** or **`+`** or **`&`** or **`%`** or **`/`** ( token becomes fingerprint )\n   * @param {boolean} [config.time=true] common representation of time such as **4pm** or **16:00 hours** (**`t`**)\n   * @param {boolean} [config.mention=true] **@mention**  as in github or twitter (**`m`**)\n   * @param {boolean} [config.url=true] URL such as **https://github.com** (**`u`**)\n   * @param {boolean} [config.word=true] word such as **faster** or **résumé** or **prévenir** (**`w`**)\n   * @return {number} number of properties set to true from the list of above 13.\n   * @example\n   * // Do not tokenize & tag @mentions.\n   * var myTokenizer.defineConfig( { mention: false } );\n   * // -> 13\n   * // Only tokenize words as defined above.\n   * var myTokenizer.defineConfig( {} );\n   * // -> 0\n  */\n  var defineConfig = function (config) {\n    if (typeof config === 'object' && Object.keys(config).length) {\n      rgxs = rgxsMaster.filter(function (rgx) {\n        // Config for the Category of `rgx`.\n        var cc = config[rgx.category];\n        // Means `undefined` & `null` values are taken as true; otherwise\n        // standard **truthy** and **falsy** interpretation applies!!\n        return cc === undefined || cc === null || !!cc;\n      });\n    } else rgxs = [];\n    // Count normalized length i.e. ignore multi-script entries.\n    const uniqueCats = Object.create(null);\n    rgxs.forEach(function (rgx) {\n      uniqueCats[rgx.category] = true;\n    });\n    // Reset the `fingerPrintCodes` variable.\n    fingerPrintCodes = {\n      emoticon: 'c',\n      email: 'e',\n      emoji: 'j',\n      hashtag: 'h',\n      mention: 'm',\n      number: 'n',\n      ordinal: 'o',\n      quoted_phrase: 'q',\n      // eslint-disable-line camelcase\n      currency: 'r',\n      // symbol: 's',\n      time: 't',\n      url: 'u',\n      word: 'w',\n      alien: 'z'\n    };\n    return Object.keys(uniqueCats).length;\n  }; // defineConfig()\n\n  // ### tokenize\n  /**\n   *\n   * Tokenizes the input `sentence` using the configuration specified via\n   * [`defineConfig()`](#defineconfig).\n   * Common contractions and possessive nouns are split into 2 separate tokens;\n   * for example **I'll** splits as `'I'` and `'\\'ll'` or **won't** splits as\n   * `'wo'` and `'n\\'t'`.\n   *\n   * @method Tokenizer#tokenize\n   * @param {string} sentence the input sentence.\n   * @return {object[]} of tokens; each one of them is an object with 2-keys viz.\n   * `value` and its `tag` identifying the type of the token.\n   * @example\n   * var s = 'For detailed API docs, check out http://winkjs.org/wink-regression-tree/ URL!';\n   * myTokenizer.tokenize( s );\n   * // -> [ { value: 'For', tag: 'word' },\n   * //      { value: 'detailed', tag: 'word' },\n   * //      { value: 'API', tag: 'word' },\n   * //      { value: 'docs', tag: 'word' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'check', tag: 'word' },\n   * //      { value: 'out', tag: 'word' },\n   * //      { value: 'http://winkjs.org/wink-regression-tree/', tag: 'url' },\n   * //      { value: 'URL', tag: 'word' },\n   * //      { value: '!', tag: 'punctuation' } ]\n  */\n  var tokenize = function (sentence) {\n    finalTokens = [];\n    tokenizeTextRecursively(sentence, rgxs);\n    return finalTokens;\n  }; // tokenize()\n\n  // ### getTokensFP\n  /**\n   *\n   * Returns the finger print of the tokens generated by the last call to\n   * [`tokenize()`](#tokenize). A finger print is a string created by sequentially\n   * joining the unique code of each token's type. Refer to table given under\n   * [`defineConfig()`](#defineconfig) for values of these codes.\n   *\n   * A finger print is extremely useful in spotting patterns present in the sentence\n   * using `regexes`, which is otherwise a complex and time consuming task.\n   *\n   * @method Tokenizer#getTokensFP\n   * @return {string} finger print of tokens generated by the last call to `tokenize()`.\n   * @example\n   * // Generate finger print of sentence given in the previous example\n   * // under tokenize().\n   * myTokenizer.getTokensFP();\n   * // -> 'wwww,wwuw!'\n  */\n  var getTokensFP = function () {\n    var fp = [];\n    finalTokens.forEach(function (t) {\n      fp.push(fingerPrintCodes[t.tag] ? fingerPrintCodes[t.tag] : t.value);\n    });\n    return fp.join('');\n  }; // getFingerprint()\n\n  // ### addTag\n  var addTag = function (name, fingerprintCode) {\n    if (fingerPrintCodes[name]) {\n      throw new Error('Tag ' + name + ' already exists');\n    }\n    fingerPrintCodes[name] = fingerprintCode;\n  }; // addTag()\n\n  // ### addRegex\n  /**\n   * Adds a regex for parsing a new type of token. This regex can either be mapped\n   * to an existing tag or it allows creation of a new tag along with its finger print.\n   * The uniqueness of the [finger prints](#defineconfig) have to ensured by the user.\n   *\n   * *The added regex(s) will supersede the internal parsing.*\n   *\n   * @method Tokenizer#addRegex\n   * @param {RegExp} regex the new regular expression.\n   * @param {string} tag tokens matching the `regex` will be assigned this tag.\n   * @param {string} [fingerprintCode=undefined] required if adding a new\n   * tag; ignored if using an existing tag.\n   * @return {void} nothing!\n   * @example\n   * // Adding a regex for an existing tag\n   * myTokenizer.addRegex( /\\(oo\\)/gi, 'emoticon' );\n   * myTokenizer.tokenize( '(oo) Hi!' )\n   * // -> [ { value: '(oo)', tag: 'emoticon' },\n   * //      { value: 'Hi', tag: 'word' },\n   * //      { value: '!', tag: 'punctuation' } ]\n   *\n   * // Adding a regex to parse a new token type\n   * myTokenizer.addRegex( /hello/gi, 'greeting', 'g' );\n   * myTokenizer.tokenize( 'hello, how are you?' );\n   * // -> [ { value: 'hello', tag: 'greeting' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'how', tag: 'word' },\n   * //      { value: 'are', tag: 'word' },\n   * //      { value: 'you', tag: 'word' },\n   * //      { value: '?', tag: 'punctuation' } ]\n   * // Notice how \"hello\" is now tagged as \"greeting\" and not as \"word\".\n   *\n   * // Using definConfig will reset the above!\n   * myTokenizer.defineConfig( { word: true } );\n   * myTokenizer.tokenize( 'hello, how are you?' );\n   * // -> [ { value: 'hello', tag: 'word' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'how', tag: 'word' },\n   * //      { value: 'are', tag: 'word' },\n   * //      { value: 'you', tag: 'word' },\n   * //      { value: '?', tag: 'punctuation' } ]\n  */\n\n  var addRegex = function (regex, tag, fingerprintCode) {\n    if (!fingerPrintCodes[tag] && !fingerprintCode) {\n      throw new Error('Tag ' + tag + ' doesn\\'t exist; Provide a \\'fingerprintCode\\' to add it as a tag.');\n    } else if (!fingerPrintCodes[tag]) {\n      addTag(tag, fingerprintCode);\n    }\n    rgxs.unshift({\n      regex: regex,\n      category: tag\n    });\n  }; // addRegex()\n\n  // Set quoted_phrase as false becuase mostly it is not required.\n  defineConfig({\n    quoted_phrase: false\n  }); // eslint-disable-line camelcase\n  methods.defineConfig = defineConfig;\n  methods.tokenize = tokenize;\n  methods.getTokensFP = getTokensFP;\n  methods.addTag = addTag;\n  methods.addRegex = addRegex;\n  return methods;\n};\nmodule.exports = tokenizer;","map":{"version":3,"names":["emojiRegex","require","contractions","rgxSpaces","rgxOrdinalL1","rgxNumberL1","rgxNumberDV","rgxMention","rgxHashtagL1","rgxHashtagDV","rgxEmail","rgxCurrency","rgxPunctuation","rgxQuotedPhrase","rgxURL","rgxEmoji","rgxEmoticon","rgxTime","rgxWordL1","rgxWordDV","rgxSymbol","rgxContraction","rgxPosSingular","rgxPosPlural","rgxsMaster","regex","category","fingerPrintCodes","emoticon","email","emoji","hashtag","mention","number","ordinal","quoted_phrase","currency","time","url","word","alien","tokenizer","rgxs","slice","finalTokens","methods","Object","create","manageContraction","tokens","ct","matches","undefined","match","push","value","tag","assign","tokenizeTextUnit","text","rgxSplit","balance","split","aword","i","imax","k","t","length","trim","test","tokenizeTextRecursively","regexes","sentence","forEach","tkn","rgx","defineConfig","config","keys","filter","cc","uniqueCats","tokenize","getTokensFP","fp","join","addTag","name","fingerprintCode","Error","addRegex","unshift","module","exports"],"sources":["C:/Users/cheko/Desktop/Education/Freelance/criticowl-main/criticowl_frontend/node_modules/wink-tokenizer/src/wink-tokenizer.js"],"sourcesContent":["//     wink-tokenizer\n//     Multilingual tokenizer that automatically tags each token with its type.\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-tokenizer”.\n//\n//     Permission is hereby granted, free of charge, to any person obtaining a\n//     copy of this software and associated documentation files (the \"Software\"),\n//     to deal in the Software without restriction, including without limitation\n//     the rights to use, copy, modify, merge, publish, distribute, sublicense,\n//     and/or sell copies of the Software, and to permit persons to whom the\n//     Software is furnished to do so, subject to the following conditions:\n//\n//     The above copyright notice and this permission notice shall be included\n//     in all copies or substantial portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\nvar emojiRegex = require( 'emoji-regex' );\nvar contractions = require( './eng-contractions.js' );\nvar rgxSpaces = /\\s+/g;\n// Ordinals only for Latin like 1st, 2nd or 12th or 33rd.\nvar rgxOrdinalL1 = /1\\dth|[04-9]th|1st|2nd|3rd|[02-9]1st|[02-9]2nd|[02-9]3rd|[02-9][04-9]th|\\d+\\d[04-9]th|\\d+\\d1st|\\d+\\d2nd|\\d+\\d3rd/g;\n// Apart from detecting pure integers or decimals, also detect numbers containing\n// `. - / ,` so that dates, ip address, fractions and things like codes or part\n// numbers are also detected as numbers only. These regex will therefore detected\n// 8.8.8.8 or 12-12-1924 or 1,1,1,1.00 or 1/4 or 1/4/66/777 as numbers.\n// Latin-1 Numbers.\nvar rgxNumberL1 = /\\d+\\/\\d+|\\d(?:[\\.,-\\/]?\\d)*(?:\\.\\d+)?/g;\n// Devanagari Numbers.\nvar rgxNumberDV = /[\\u0966-\\u096F]+\\/[\\u0966-\\u096F]+|[\\u0966-\\u096F](?:[\\.,-\\/]?[\\u0966-\\u096F])*(?:\\.[\\u0966-\\u096F]+)?/g;\nvar rgxMention = /@\\w+/g;\n// Latin-1 Hashtags.\n// Include entire Latin-1 script and not just English alphas.\nvar rgxHashtagL1 = /#[a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF_][a-z0-9\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF_]*/gi;\n// Devanagari Hashtags\nvar rgxHashtagDV = /#[\\u0900-\\u0963\\u0970-\\u097F_][\\u0900-\\u0963\\u0970-\\u097F\\u0966-\\u096F0-9_]*/gi;\n// EMail is EN character set.\nvar rgxEmail = /[-!#$%&'*+\\/=?^\\w{|}~](?:\\.?[-!#$%&'*+\\/=?^\\w`{|}~])*@[a-z0-9](?:-?\\.?[a-z0-9])*(?:\\.[a-z](?:-?[a-z0-9])*)+/gi;\n// Bitcoin, Ruble, Indian Rupee, Other Rupee, Dollar, Pound, Yen, Euro, Wong.\nvar rgxCurrency = /[₿₽₹₨$£¥€₩]/g;\n// These include both the punctuations: Latin-1 & Devanagari.\nvar rgxPunctuation = /[’'‘’`“”\"\\[\\]\\(\\){}…,\\.!;\\?\\-:\\u0964\\u0965]/g;\nvar rgxQuotedPhrase = /\"[^\"]*\"/g;\n// NOTE: URL will support only EN character set for now.\nvar rgxURL = /(?:https?:\\/\\/)(?:[\\da-z\\.-]+)\\.(?:[a-z\\.]{2,6})(?:[\\/\\w\\.\\-\\?#=]*)*\\/?/gi;\nvar rgxEmoji = emojiRegex();\nvar rgxEmoticon = /:-?[dps\\*\\/\\[\\]{}\\(\\)]|;-?[/(/)d]|<3/gi;\nvar rgxTime = /(?:\\d|[01]\\d|2[0-3]):?(?:[0-5][0-9])?\\s?(?:[ap]\\.?m\\.?|hours|hrs)/gi;\n// Inlcude [Latin-1 Supplement Unicode Block](https://en.wikipedia.org/wiki/Latin-1_Supplement_(Unicode_block))\nvar rgxWordL1 = /[a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF][a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u00FF']*/gi;\n// Define [Devanagari Unicode Block](https://unicode.org/charts/PDF/U0900.pdf)\nvar rgxWordDV = /[\\u0900-\\u094F\\u0951-\\u0963\\u0970-\\u097F]+/gi;\n// Symbols go here; including Om.\nvar rgxSymbol = /[\\u0950~@#%\\^\\+=\\*\\|\\/<>&]/g;\n// For detecting if the word is a potential contraction.\nvar rgxContraction = /'/;\n// Singular & Plural possessive\nvar rgxPosSingular = /([a-z]+)('s)$/i;\nvar rgxPosPlural = /([a-z]+s)(')$/i;\n// Regexes and their categories; used for tokenizing via match/split. The\n// sequence is *critical* for correct tokenization.\nvar rgxsMaster = [\n  { regex: rgxQuotedPhrase, category: 'quoted_phrase' },\n  { regex: rgxURL, category: 'url' },\n  { regex: rgxEmail, category: 'email' },\n  { regex: rgxMention, category: 'mention' },\n  { regex: rgxHashtagL1, category: 'hashtag' },\n  { regex: rgxHashtagDV, category: 'hashtag' },\n  { regex: rgxEmoji, category: 'emoji' },\n  { regex: rgxEmoticon, category: 'emoticon' },\n  { regex: rgxTime, category: 'time' },\n  { regex: rgxOrdinalL1, category: 'ordinal' },\n  { regex: rgxNumberL1, category: 'number' },\n  { regex: rgxNumberDV, category: 'number' },\n  { regex: rgxCurrency, category: 'currency' },\n  { regex: rgxWordL1, category: 'word' },\n  { regex: rgxWordDV, category: 'word' },\n  { regex: rgxPunctuation, category: 'punctuation' },\n  { regex: rgxSymbol, category: 'symbol' }\n];\n\n// Used to generate finger print from the tokens.\n// NOTE: this variable is being reset in `defineConfig()`.\nvar fingerPrintCodes = {\n  emoticon: 'c',\n  email: 'e',\n  emoji: 'j',\n  hashtag: 'h',\n  mention: 'm',\n  number: 'n',\n  ordinal: 'o',\n  quoted_phrase: 'q', // eslint-disable-line camelcase\n  currency: 'r',\n  // symbol: 's',\n  time: 't',\n  url: 'u',\n  word: 'w',\n  alien: 'z'\n};\n\n// ### tokenizer\n/**\n *\n * Creates an instance of {@link Tokenizer}.\n *\n * @return {Tokenizer} object conatining set of API methods for tokenizing a sentence\n * and defining configuration, plugin etc.\n * @example\n * // Load wink tokenizer.\n * var tokenizer = require( 'wink-tokenizer' );\n * // Create your instance of wink tokenizer.\n * var myTokenizer = tokenizer();\n*/\nvar tokenizer = function () {\n  // Default configuration: most comprehensive tokenization. Make deep copy!\n  var rgxs = rgxsMaster.slice( 0 );\n  // The result of last call to `tokenize()` is retained here.\n  var finalTokens = [];\n  // Returned!\n\n  /**\n   * @classdesc Tokenizer class\n   * @class Tokenizer\n   * @hideconstructor\n   */\n  var methods = Object.create( null );\n\n  // ### manageContraction\n  /**\n   *\n   * Splits a contractions into words by first trying a lookup in strandard\n   * `contractions`; if the lookup fails, it checks for possessive in `'s` or\n   * `s'` forms and separates the possesive part from the word. Otherwise the\n   * contraction is treated as a normal word and no splitting occurs.\n   *\n   * @param {string} word that could be a potential conraction.\n   * @param {object[]} tokens where the outcome is pushed.\n   * @return {object[]} updated tokens according to the `word.`\n   * @private\n  */\n  var manageContraction = function ( word, tokens ) {\n    var ct = contractions[ word ];\n    var matches;\n    if ( ct === undefined ) {\n      // Try possesive of sigular & plural forms\n      matches = word.match( rgxPosSingular );\n      if ( matches ) {\n        tokens.push( { value: matches[ 1 ], tag: 'word' } );\n        tokens.push( { value: matches[ 2 ], tag: 'word' } );\n      } else {\n        matches = word.match( rgxPosPlural );\n        if ( matches ) {\n          tokens.push( { value: matches[ 1 ], tag: 'word' } );\n          tokens.push( { value: matches[ 2 ], tag: 'word' } );\n        } else tokens.push( { value: word, tag: 'word' } );\n      }\n    } else {\n      // Manage via lookup; ensure cloning!\n      tokens.push( Object.assign( {}, ct[ 0 ] ) );\n      tokens.push( Object.assign( {}, ct[ 1 ] ) );\n      if ( ct[ 2 ] ) tokens.push( Object.assign( {}, ct[ 2 ] ) );\n    }\n    return tokens;\n  }; // manageContraction()\n\n  // ### tokenizeTextUnit\n  /**\n   *\n   * Attempts to tokenize the input `text` using the `rgxSplit`. The tokenization\n   * is carried out by combining the regex matches and splits in the right sequence.\n   * The matches are the *real tokens*, whereas splits are text units that are\n   * tokenized in later rounds! The real tokens (i.e. matches) are pushed as\n   * `object` and splits as `string`.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} rgxSplit object containing the regex and it's category.\n   * @return {array} of tokens.\n   * @private\n  */\n  var tokenizeTextUnit = function ( text, rgxSplit ) {\n    // Regex matches go here; note each match is a token and has the same tag\n    // as of regex's category.\n    var matches = text.match( rgxSplit.regex );\n    // Balance is \"what needs to be tokenized\".\n    var balance = text.split( rgxSplit.regex );\n    // The result, in form of combination of tokens & matches, is captured here.\n    var tokens = [];\n    // The tag;\n    var tag = rgxSplit.category;\n    // Helper variables.\n    var aword,\n        i,\n        imax,\n        k = 0,\n        t;\n\n    // Combine tokens & matches in the following pattern [ b0 m0 b1 m1 ... ]\n    matches = ( matches ) ? matches : [];\n    for ( i = 0, imax = balance.length; i < imax; i += 1 ) {\n      t = balance[ i ];\n      t = t.trim();\n      if ( t ) tokens.push( t );\n      if ( k < matches.length ) {\n        if ( tag === 'word' ) {\n          // Tag type `word` token may have a contraction.\n          aword = matches[ k ];\n          if ( rgxContraction.test( aword ) ) {\n            tokens = manageContraction( aword, tokens );\n          } else {\n            // Means there is no contraction.\n            tokens.push( { value: aword, tag: tag } );\n          }\n        } else tokens.push( { value: matches[ k ], tag: tag } );\n      }\n      k += 1;\n    }\n\n    return ( tokens );\n  }; // tokenizeTextUnit()\n\n  // ### tokenizeTextRecursively\n  /**\n   *\n   * Tokenizes the input text recursively using the array of `regexes` and then\n   * the `tokenizeTextUnit()` function. If (or whenever) the `regexes` becomes\n   * empty, it simply splits the text on non-word characters instead of using\n   * the `tokenizeTextUnit()` function.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} regexes object containing the regex and it's category.\n   * @return {undefined} nothing!\n   * @private\n  */\n  var tokenizeTextRecursively = function ( text, regexes ) {\n    var sentence = text.trim();\n    var tokens = [];\n    var i, imax;\n\n    if ( !regexes.length ) {\n      // No regex left, split on `spaces` and tag every token as **alien**.\n      text.split( rgxSpaces ).forEach( function ( tkn ) {\n        finalTokens.push( { value: tkn.trim(), tag: 'alien' } );\n      } );\n      return;\n    }\n\n    var rgx = regexes[ 0 ];\n    tokens = tokenizeTextUnit( sentence, rgx );\n\n    for ( i = 0, imax = tokens.length; i < imax; i += 1 ) {\n      if ( typeof tokens[ i ] === 'string' ) {\n        // Strings become candidates for further tokenization.\n        tokenizeTextRecursively( tokens[ i ], regexes.slice( 1 ) );\n      } else {\n        finalTokens.push( tokens[ i ] );\n      }\n    }\n  }; // tokenizeTextRecursively()\n\n  // ### defineConfig\n  /**\n   *\n   * Defines the configuration in terms of the types of token that will be\n   * extracted by [`tokenize()`](#tokenize) method. Note by default, all types\n   * of tokens will be detected and tagged automatically.\n   *\n   * @method Tokenizer#defineConfig\n   * @param {object} config It defines 0 or more properties from the list of\n   * **14** properties. A true value for a property ensures tokenization\n   * for that type of text; whereas false value will mean that the tokenization of that\n   * type of text will not be attempted. It also **resets** the effect of any previous\n   * call(s) to the [`addRegex()`](#addregex) API.\n   *\n   * *An empty config object is equivalent to splitting on spaces. Whatever tokens\n   * are created like this are tagged as **alien** and **`z`** is the\n   * [finger print](#gettokensfp) code of this token type.*\n   *\n   * The table below gives the name of each property and it's description including\n   * examples. The character with in paranthesis is the [finger print](#gettokensfp) code for the\n   * token of that type.\n   * @param {boolean} [config.currency=true] such as **$** or **£** symbols (**`r`**)\n   * @param {boolean} [config.email=true] for example **john@acme.com** or **superman1@gmail.com** (**`e`**)\n   * @param {boolean} [config.emoji=true] any standard unicode emojis e.g. 😊 or 😂 or 🎉 (**`j`**)\n   * @param {boolean} [config.emoticon=true] common emoticons such as **`:-)`** or **`:D`** (**`c`**)\n   * @param {boolean} [config.hashtag=true] hash tags such as **`#happy`** or **`#followme`** (**`h`**)\n   * @param {boolean} [config.number=true] any integer, decimal number, fractions such as **19**, **2.718**\n   * or **1/4** and numerals containing \"**`, - / .`**\", for example 12-12-1924 (**`n`**)\n   * @param {boolean} [config.ordinal=true] ordinals like **1st**, **2nd**, **3rd**, **4th** or **12th** or **91st** (**`o`**)\n   * @param {boolean} [config.punctuation=true] common punctuation such as **`?`** or **`,`**\n   * ( token becomes fingerprint )\n   * @param {boolean} [config.quoted_phrase=false] any **\"quoted text\"** in the sentence. _Note: its default value is **false**._ (**`q`**)\n   * @param {boolean} [config.symbol=true] for example **`~`** or **`+`** or **`&`** or **`%`** or **`/`** ( token becomes fingerprint )\n   * @param {boolean} [config.time=true] common representation of time such as **4pm** or **16:00 hours** (**`t`**)\n   * @param {boolean} [config.mention=true] **@mention**  as in github or twitter (**`m`**)\n   * @param {boolean} [config.url=true] URL such as **https://github.com** (**`u`**)\n   * @param {boolean} [config.word=true] word such as **faster** or **résumé** or **prévenir** (**`w`**)\n   * @return {number} number of properties set to true from the list of above 13.\n   * @example\n   * // Do not tokenize & tag @mentions.\n   * var myTokenizer.defineConfig( { mention: false } );\n   * // -> 13\n   * // Only tokenize words as defined above.\n   * var myTokenizer.defineConfig( {} );\n   * // -> 0\n  */\n  var defineConfig = function ( config ) {\n    if ( typeof config === 'object' && Object.keys( config ).length ) {\n      rgxs = rgxsMaster.filter( function ( rgx ) {\n        // Config for the Category of `rgx`.\n        var cc = config[ rgx.category ];\n        // Means `undefined` & `null` values are taken as true; otherwise\n        // standard **truthy** and **falsy** interpretation applies!!\n        return ( cc === undefined || cc === null || !!cc );\n      } );\n    } else rgxs = [];\n    // Count normalized length i.e. ignore multi-script entries.\n    const uniqueCats = Object.create( null );\n    rgxs.forEach( function ( rgx ) {\n      uniqueCats[ rgx.category ] = true;\n    } );\n    // Reset the `fingerPrintCodes` variable.\n    fingerPrintCodes = {\n      emoticon: 'c',\n      email: 'e',\n      emoji: 'j',\n      hashtag: 'h',\n      mention: 'm',\n      number: 'n',\n      ordinal: 'o',\n      quoted_phrase: 'q', // eslint-disable-line camelcase\n      currency: 'r',\n      // symbol: 's',\n      time: 't',\n      url: 'u',\n      word: 'w',\n      alien: 'z'\n    };\n    return ( ( Object.keys( uniqueCats ) ).length );\n  }; // defineConfig()\n\n  // ### tokenize\n  /**\n   *\n   * Tokenizes the input `sentence` using the configuration specified via\n   * [`defineConfig()`](#defineconfig).\n   * Common contractions and possessive nouns are split into 2 separate tokens;\n   * for example **I'll** splits as `'I'` and `'\\'ll'` or **won't** splits as\n   * `'wo'` and `'n\\'t'`.\n   *\n   * @method Tokenizer#tokenize\n   * @param {string} sentence the input sentence.\n   * @return {object[]} of tokens; each one of them is an object with 2-keys viz.\n   * `value` and its `tag` identifying the type of the token.\n   * @example\n   * var s = 'For detailed API docs, check out http://winkjs.org/wink-regression-tree/ URL!';\n   * myTokenizer.tokenize( s );\n   * // -> [ { value: 'For', tag: 'word' },\n   * //      { value: 'detailed', tag: 'word' },\n   * //      { value: 'API', tag: 'word' },\n   * //      { value: 'docs', tag: 'word' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'check', tag: 'word' },\n   * //      { value: 'out', tag: 'word' },\n   * //      { value: 'http://winkjs.org/wink-regression-tree/', tag: 'url' },\n   * //      { value: 'URL', tag: 'word' },\n   * //      { value: '!', tag: 'punctuation' } ]\n  */\n  var tokenize = function ( sentence ) {\n    finalTokens = [];\n    tokenizeTextRecursively( sentence, rgxs );\n    return finalTokens;\n  }; // tokenize()\n\n  // ### getTokensFP\n  /**\n   *\n   * Returns the finger print of the tokens generated by the last call to\n   * [`tokenize()`](#tokenize). A finger print is a string created by sequentially\n   * joining the unique code of each token's type. Refer to table given under\n   * [`defineConfig()`](#defineconfig) for values of these codes.\n   *\n   * A finger print is extremely useful in spotting patterns present in the sentence\n   * using `regexes`, which is otherwise a complex and time consuming task.\n   *\n   * @method Tokenizer#getTokensFP\n   * @return {string} finger print of tokens generated by the last call to `tokenize()`.\n   * @example\n   * // Generate finger print of sentence given in the previous example\n   * // under tokenize().\n   * myTokenizer.getTokensFP();\n   * // -> 'wwww,wwuw!'\n  */\n  var getTokensFP = function () {\n    var fp = [];\n    finalTokens.forEach( function ( t ) {\n      fp.push( ( fingerPrintCodes[ t.tag ] ) ? fingerPrintCodes[ t.tag ] : t.value );\n    } );\n    return fp.join( '' );\n  }; // getFingerprint()\n\n  // ### addTag\n  var addTag = function (name, fingerprintCode) {\n    if (fingerPrintCodes[name]) {\n      throw new Error( 'Tag ' + name + ' already exists' );\n    }\n\n    fingerPrintCodes[name] = fingerprintCode;\n  }; // addTag()\n\n  // ### addRegex\n  /**\n   * Adds a regex for parsing a new type of token. This regex can either be mapped\n   * to an existing tag or it allows creation of a new tag along with its finger print.\n   * The uniqueness of the [finger prints](#defineconfig) have to ensured by the user.\n   *\n   * *The added regex(s) will supersede the internal parsing.*\n   *\n   * @method Tokenizer#addRegex\n   * @param {RegExp} regex the new regular expression.\n   * @param {string} tag tokens matching the `regex` will be assigned this tag.\n   * @param {string} [fingerprintCode=undefined] required if adding a new\n   * tag; ignored if using an existing tag.\n   * @return {void} nothing!\n   * @example\n   * // Adding a regex for an existing tag\n   * myTokenizer.addRegex( /\\(oo\\)/gi, 'emoticon' );\n   * myTokenizer.tokenize( '(oo) Hi!' )\n   * // -> [ { value: '(oo)', tag: 'emoticon' },\n   * //      { value: 'Hi', tag: 'word' },\n   * //      { value: '!', tag: 'punctuation' } ]\n   *\n   * // Adding a regex to parse a new token type\n   * myTokenizer.addRegex( /hello/gi, 'greeting', 'g' );\n   * myTokenizer.tokenize( 'hello, how are you?' );\n   * // -> [ { value: 'hello', tag: 'greeting' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'how', tag: 'word' },\n   * //      { value: 'are', tag: 'word' },\n   * //      { value: 'you', tag: 'word' },\n   * //      { value: '?', tag: 'punctuation' } ]\n   * // Notice how \"hello\" is now tagged as \"greeting\" and not as \"word\".\n   *\n   * // Using definConfig will reset the above!\n   * myTokenizer.defineConfig( { word: true } );\n   * myTokenizer.tokenize( 'hello, how are you?' );\n   * // -> [ { value: 'hello', tag: 'word' },\n   * //      { value: ',', tag: 'punctuation' },\n   * //      { value: 'how', tag: 'word' },\n   * //      { value: 'are', tag: 'word' },\n   * //      { value: 'you', tag: 'word' },\n   * //      { value: '?', tag: 'punctuation' } ]\n  */\n\n  var addRegex = function (regex, tag, fingerprintCode) {\n    if (!fingerPrintCodes[tag] && !fingerprintCode) {\n      throw new Error( 'Tag ' + tag + ' doesn\\'t exist; Provide a \\'fingerprintCode\\' to add it as a tag.' );\n    } else if (!fingerPrintCodes[tag]) {\n      addTag(tag, fingerprintCode);\n    }\n\n    rgxs.unshift( { regex: regex, category: tag } );\n  }; // addRegex()\n\n  // Set quoted_phrase as false becuase mostly it is not required.\n  defineConfig( { quoted_phrase: false } ); // eslint-disable-line camelcase\n  methods.defineConfig = defineConfig;\n  methods.tokenize = tokenize;\n  methods.getTokensFP = getTokensFP;\n  methods.addTag = addTag;\n  methods.addRegex = addRegex;\n  return methods;\n};\n\nmodule.exports = tokenizer;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,IAAIA,UAAU,GAAGC,OAAO,CAAE,aAAc,CAAC;AACzC,IAAIC,YAAY,GAAGD,OAAO,CAAE,uBAAwB,CAAC;AACrD,IAAIE,SAAS,GAAG,MAAM;AACtB;AACA,IAAIC,YAAY,GAAG,mHAAmH;AACtI;AACA;AACA;AACA;AACA;AACA,IAAIC,WAAW,GAAG,wCAAwC;AAC1D;AACA,IAAIC,WAAW,GAAG,yGAAyG;AAC3H,IAAIC,UAAU,GAAG,OAAO;AACxB;AACA;AACA,IAAIC,YAAY,GAAG,mGAAmG;AACtH;AACA,IAAIC,YAAY,GAAG,gFAAgF;AACnG;AACA,IAAIC,QAAQ,GAAG,+GAA+G;AAC9H;AACA,IAAIC,WAAW,GAAG,cAAc;AAChC;AACA,IAAIC,cAAc,GAAG,8CAA8C;AACnE,IAAIC,eAAe,GAAG,UAAU;AAChC;AACA,IAAIC,MAAM,GAAG,2EAA2E;AACxF,IAAIC,QAAQ,GAAGf,UAAU,CAAC,CAAC;AAC3B,IAAIgB,WAAW,GAAG,wCAAwC;AAC1D,IAAIC,OAAO,GAAG,qEAAqE;AACnF;AACA,IAAIC,SAAS,GAAG,8FAA8F;AAC9G;AACA,IAAIC,SAAS,GAAG,8CAA8C;AAC9D;AACA,IAAIC,SAAS,GAAG,6BAA6B;AAC7C;AACA,IAAIC,cAAc,GAAG,GAAG;AACxB;AACA,IAAIC,cAAc,GAAG,gBAAgB;AACrC,IAAIC,YAAY,GAAG,gBAAgB;AACnC;AACA;AACA,IAAIC,UAAU,GAAG,CACf;EAAEC,KAAK,EAAEZ,eAAe;EAAEa,QAAQ,EAAE;AAAgB,CAAC,EACrD;EAAED,KAAK,EAAEX,MAAM;EAAEY,QAAQ,EAAE;AAAM,CAAC,EAClC;EAAED,KAAK,EAAEf,QAAQ;EAAEgB,QAAQ,EAAE;AAAQ,CAAC,EACtC;EAAED,KAAK,EAAElB,UAAU;EAAEmB,QAAQ,EAAE;AAAU,CAAC,EAC1C;EAAED,KAAK,EAAEjB,YAAY;EAAEkB,QAAQ,EAAE;AAAU,CAAC,EAC5C;EAAED,KAAK,EAAEhB,YAAY;EAAEiB,QAAQ,EAAE;AAAU,CAAC,EAC5C;EAAED,KAAK,EAAEV,QAAQ;EAAEW,QAAQ,EAAE;AAAQ,CAAC,EACtC;EAAED,KAAK,EAAET,WAAW;EAAEU,QAAQ,EAAE;AAAW,CAAC,EAC5C;EAAED,KAAK,EAAER,OAAO;EAAES,QAAQ,EAAE;AAAO,CAAC,EACpC;EAAED,KAAK,EAAErB,YAAY;EAAEsB,QAAQ,EAAE;AAAU,CAAC,EAC5C;EAAED,KAAK,EAAEpB,WAAW;EAAEqB,QAAQ,EAAE;AAAS,CAAC,EAC1C;EAAED,KAAK,EAAEnB,WAAW;EAAEoB,QAAQ,EAAE;AAAS,CAAC,EAC1C;EAAED,KAAK,EAAEd,WAAW;EAAEe,QAAQ,EAAE;AAAW,CAAC,EAC5C;EAAED,KAAK,EAAEP,SAAS;EAAEQ,QAAQ,EAAE;AAAO,CAAC,EACtC;EAAED,KAAK,EAAEN,SAAS;EAAEO,QAAQ,EAAE;AAAO,CAAC,EACtC;EAAED,KAAK,EAAEb,cAAc;EAAEc,QAAQ,EAAE;AAAc,CAAC,EAClD;EAAED,KAAK,EAAEL,SAAS;EAAEM,QAAQ,EAAE;AAAS,CAAC,CACzC;;AAED;AACA;AACA,IAAIC,gBAAgB,GAAG;EACrBC,QAAQ,EAAE,GAAG;EACbC,KAAK,EAAE,GAAG;EACVC,KAAK,EAAE,GAAG;EACVC,OAAO,EAAE,GAAG;EACZC,OAAO,EAAE,GAAG;EACZC,MAAM,EAAE,GAAG;EACXC,OAAO,EAAE,GAAG;EACZC,aAAa,EAAE,GAAG;EAAE;EACpBC,QAAQ,EAAE,GAAG;EACb;EACAC,IAAI,EAAE,GAAG;EACTC,GAAG,EAAE,GAAG;EACRC,IAAI,EAAE,GAAG;EACTC,KAAK,EAAE;AACT,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIC,SAAS,GAAG,SAAAA,CAAA,EAAY;EAC1B;EACA,IAAIC,IAAI,GAAGlB,UAAU,CAACmB,KAAK,CAAE,CAAE,CAAC;EAChC;EACA,IAAIC,WAAW,GAAG,EAAE;EACpB;;EAEA;AACF;AACA;AACA;AACA;EACE,IAAIC,OAAO,GAAGC,MAAM,CAACC,MAAM,CAAE,IAAK,CAAC;;EAEnC;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIC,iBAAiB,GAAG,SAAAA,CAAWT,IAAI,EAAEU,MAAM,EAAG;IAChD,IAAIC,EAAE,GAAGhD,YAAY,CAAEqC,IAAI,CAAE;IAC7B,IAAIY,OAAO;IACX,IAAKD,EAAE,KAAKE,SAAS,EAAG;MACtB;MACAD,OAAO,GAAGZ,IAAI,CAACc,KAAK,CAAE/B,cAAe,CAAC;MACtC,IAAK6B,OAAO,EAAG;QACbF,MAAM,CAACK,IAAI,CAAE;UAAEC,KAAK,EAAEJ,OAAO,CAAE,CAAC,CAAE;UAAEK,GAAG,EAAE;QAAO,CAAE,CAAC;QACnDP,MAAM,CAACK,IAAI,CAAE;UAAEC,KAAK,EAAEJ,OAAO,CAAE,CAAC,CAAE;UAAEK,GAAG,EAAE;QAAO,CAAE,CAAC;MACrD,CAAC,MAAM;QACLL,OAAO,GAAGZ,IAAI,CAACc,KAAK,CAAE9B,YAAa,CAAC;QACpC,IAAK4B,OAAO,EAAG;UACbF,MAAM,CAACK,IAAI,CAAE;YAAEC,KAAK,EAAEJ,OAAO,CAAE,CAAC,CAAE;YAAEK,GAAG,EAAE;UAAO,CAAE,CAAC;UACnDP,MAAM,CAACK,IAAI,CAAE;YAAEC,KAAK,EAAEJ,OAAO,CAAE,CAAC,CAAE;YAAEK,GAAG,EAAE;UAAO,CAAE,CAAC;QACrD,CAAC,MAAMP,MAAM,CAACK,IAAI,CAAE;UAAEC,KAAK,EAAEhB,IAAI;UAAEiB,GAAG,EAAE;QAAO,CAAE,CAAC;MACpD;IACF,CAAC,MAAM;MACL;MACAP,MAAM,CAACK,IAAI,CAAER,MAAM,CAACW,MAAM,CAAE,CAAC,CAAC,EAAEP,EAAE,CAAE,CAAC,CAAG,CAAE,CAAC;MAC3CD,MAAM,CAACK,IAAI,CAAER,MAAM,CAACW,MAAM,CAAE,CAAC,CAAC,EAAEP,EAAE,CAAE,CAAC,CAAG,CAAE,CAAC;MAC3C,IAAKA,EAAE,CAAE,CAAC,CAAE,EAAGD,MAAM,CAACK,IAAI,CAAER,MAAM,CAACW,MAAM,CAAE,CAAC,CAAC,EAAEP,EAAE,CAAE,CAAC,CAAG,CAAE,CAAC;IAC5D;IACA,OAAOD,MAAM;EACf,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIS,gBAAgB,GAAG,SAAAA,CAAWC,IAAI,EAAEC,QAAQ,EAAG;IACjD;IACA;IACA,IAAIT,OAAO,GAAGQ,IAAI,CAACN,KAAK,CAAEO,QAAQ,CAACnC,KAAM,CAAC;IAC1C;IACA,IAAIoC,OAAO,GAAGF,IAAI,CAACG,KAAK,CAAEF,QAAQ,CAACnC,KAAM,CAAC;IAC1C;IACA,IAAIwB,MAAM,GAAG,EAAE;IACf;IACA,IAAIO,GAAG,GAAGI,QAAQ,CAAClC,QAAQ;IAC3B;IACA,IAAIqC,KAAK;MACLC,CAAC;MACDC,IAAI;MACJC,CAAC,GAAG,CAAC;MACLC,CAAC;;IAEL;IACAhB,OAAO,GAAKA,OAAO,GAAKA,OAAO,GAAG,EAAE;IACpC,KAAMa,CAAC,GAAG,CAAC,EAAEC,IAAI,GAAGJ,OAAO,CAACO,MAAM,EAAEJ,CAAC,GAAGC,IAAI,EAAED,CAAC,IAAI,CAAC,EAAG;MACrDG,CAAC,GAAGN,OAAO,CAAEG,CAAC,CAAE;MAChBG,CAAC,GAAGA,CAAC,CAACE,IAAI,CAAC,CAAC;MACZ,IAAKF,CAAC,EAAGlB,MAAM,CAACK,IAAI,CAAEa,CAAE,CAAC;MACzB,IAAKD,CAAC,GAAGf,OAAO,CAACiB,MAAM,EAAG;QACxB,IAAKZ,GAAG,KAAK,MAAM,EAAG;UACpB;UACAO,KAAK,GAAGZ,OAAO,CAAEe,CAAC,CAAE;UACpB,IAAK7C,cAAc,CAACiD,IAAI,CAAEP,KAAM,CAAC,EAAG;YAClCd,MAAM,GAAGD,iBAAiB,CAAEe,KAAK,EAAEd,MAAO,CAAC;UAC7C,CAAC,MAAM;YACL;YACAA,MAAM,CAACK,IAAI,CAAE;cAAEC,KAAK,EAAEQ,KAAK;cAAEP,GAAG,EAAEA;YAAI,CAAE,CAAC;UAC3C;QACF,CAAC,MAAMP,MAAM,CAACK,IAAI,CAAE;UAAEC,KAAK,EAAEJ,OAAO,CAAEe,CAAC,CAAE;UAAEV,GAAG,EAAEA;QAAI,CAAE,CAAC;MACzD;MACAU,CAAC,IAAI,CAAC;IACR;IAEA,OAASjB,MAAM;EACjB,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIsB,uBAAuB,GAAG,SAAAA,CAAWZ,IAAI,EAAEa,OAAO,EAAG;IACvD,IAAIC,QAAQ,GAAGd,IAAI,CAACU,IAAI,CAAC,CAAC;IAC1B,IAAIpB,MAAM,GAAG,EAAE;IACf,IAAIe,CAAC,EAAEC,IAAI;IAEX,IAAK,CAACO,OAAO,CAACJ,MAAM,EAAG;MACrB;MACAT,IAAI,CAACG,KAAK,CAAE3D,SAAU,CAAC,CAACuE,OAAO,CAAE,UAAWC,GAAG,EAAG;QAChD/B,WAAW,CAACU,IAAI,CAAE;UAAEC,KAAK,EAAEoB,GAAG,CAACN,IAAI,CAAC,CAAC;UAAEb,GAAG,EAAE;QAAQ,CAAE,CAAC;MACzD,CAAE,CAAC;MACH;IACF;IAEA,IAAIoB,GAAG,GAAGJ,OAAO,CAAE,CAAC,CAAE;IACtBvB,MAAM,GAAGS,gBAAgB,CAAEe,QAAQ,EAAEG,GAAI,CAAC;IAE1C,KAAMZ,CAAC,GAAG,CAAC,EAAEC,IAAI,GAAGhB,MAAM,CAACmB,MAAM,EAAEJ,CAAC,GAAGC,IAAI,EAAED,CAAC,IAAI,CAAC,EAAG;MACpD,IAAK,OAAOf,MAAM,CAAEe,CAAC,CAAE,KAAK,QAAQ,EAAG;QACrC;QACAO,uBAAuB,CAAEtB,MAAM,CAAEe,CAAC,CAAE,EAAEQ,OAAO,CAAC7B,KAAK,CAAE,CAAE,CAAE,CAAC;MAC5D,CAAC,MAAM;QACLC,WAAW,CAACU,IAAI,CAAEL,MAAM,CAAEe,CAAC,CAAG,CAAC;MACjC;IACF;EACF,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIa,YAAY,GAAG,SAAAA,CAAWC,MAAM,EAAG;IACrC,IAAK,OAAOA,MAAM,KAAK,QAAQ,IAAIhC,MAAM,CAACiC,IAAI,CAAED,MAAO,CAAC,CAACV,MAAM,EAAG;MAChE1B,IAAI,GAAGlB,UAAU,CAACwD,MAAM,CAAE,UAAWJ,GAAG,EAAG;QACzC;QACA,IAAIK,EAAE,GAAGH,MAAM,CAAEF,GAAG,CAAClD,QAAQ,CAAE;QAC/B;QACA;QACA,OAASuD,EAAE,KAAK7B,SAAS,IAAI6B,EAAE,KAAK,IAAI,IAAI,CAAC,CAACA,EAAE;MAClD,CAAE,CAAC;IACL,CAAC,MAAMvC,IAAI,GAAG,EAAE;IAChB;IACA,MAAMwC,UAAU,GAAGpC,MAAM,CAACC,MAAM,CAAE,IAAK,CAAC;IACxCL,IAAI,CAACgC,OAAO,CAAE,UAAWE,GAAG,EAAG;MAC7BM,UAAU,CAAEN,GAAG,CAAClD,QAAQ,CAAE,GAAG,IAAI;IACnC,CAAE,CAAC;IACH;IACAC,gBAAgB,GAAG;MACjBC,QAAQ,EAAE,GAAG;MACbC,KAAK,EAAE,GAAG;MACVC,KAAK,EAAE,GAAG;MACVC,OAAO,EAAE,GAAG;MACZC,OAAO,EAAE,GAAG;MACZC,MAAM,EAAE,GAAG;MACXC,OAAO,EAAE,GAAG;MACZC,aAAa,EAAE,GAAG;MAAE;MACpBC,QAAQ,EAAE,GAAG;MACb;MACAC,IAAI,EAAE,GAAG;MACTC,GAAG,EAAE,GAAG;MACRC,IAAI,EAAE,GAAG;MACTC,KAAK,EAAE;IACT,CAAC;IACD,OAAWM,MAAM,CAACiC,IAAI,CAAEG,UAAW,CAAC,CAAGd,MAAM;EAC/C,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIe,QAAQ,GAAG,SAAAA,CAAWV,QAAQ,EAAG;IACnC7B,WAAW,GAAG,EAAE;IAChB2B,uBAAuB,CAAEE,QAAQ,EAAE/B,IAAK,CAAC;IACzC,OAAOE,WAAW;EACpB,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIwC,WAAW,GAAG,SAAAA,CAAA,EAAY;IAC5B,IAAIC,EAAE,GAAG,EAAE;IACXzC,WAAW,CAAC8B,OAAO,CAAE,UAAWP,CAAC,EAAG;MAClCkB,EAAE,CAAC/B,IAAI,CAAI3B,gBAAgB,CAAEwC,CAAC,CAACX,GAAG,CAAE,GAAK7B,gBAAgB,CAAEwC,CAAC,CAACX,GAAG,CAAE,GAAGW,CAAC,CAACZ,KAAM,CAAC;IAChF,CAAE,CAAC;IACH,OAAO8B,EAAE,CAACC,IAAI,CAAE,EAAG,CAAC;EACtB,CAAC,CAAC,CAAC;;EAEH;EACA,IAAIC,MAAM,GAAG,SAAAA,CAAUC,IAAI,EAAEC,eAAe,EAAE;IAC5C,IAAI9D,gBAAgB,CAAC6D,IAAI,CAAC,EAAE;MAC1B,MAAM,IAAIE,KAAK,CAAE,MAAM,GAAGF,IAAI,GAAG,iBAAkB,CAAC;IACtD;IAEA7D,gBAAgB,CAAC6D,IAAI,CAAC,GAAGC,eAAe;EAC1C,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;EAEE,IAAIE,QAAQ,GAAG,SAAAA,CAAUlE,KAAK,EAAE+B,GAAG,EAAEiC,eAAe,EAAE;IACpD,IAAI,CAAC9D,gBAAgB,CAAC6B,GAAG,CAAC,IAAI,CAACiC,eAAe,EAAE;MAC9C,MAAM,IAAIC,KAAK,CAAE,MAAM,GAAGlC,GAAG,GAAG,oEAAqE,CAAC;IACxG,CAAC,MAAM,IAAI,CAAC7B,gBAAgB,CAAC6B,GAAG,CAAC,EAAE;MACjC+B,MAAM,CAAC/B,GAAG,EAAEiC,eAAe,CAAC;IAC9B;IAEA/C,IAAI,CAACkD,OAAO,CAAE;MAAEnE,KAAK,EAAEA,KAAK;MAAEC,QAAQ,EAAE8B;IAAI,CAAE,CAAC;EACjD,CAAC,CAAC,CAAC;;EAEH;EACAqB,YAAY,CAAE;IAAE1C,aAAa,EAAE;EAAM,CAAE,CAAC,CAAC,CAAC;EAC1CU,OAAO,CAACgC,YAAY,GAAGA,YAAY;EACnChC,OAAO,CAACsC,QAAQ,GAAGA,QAAQ;EAC3BtC,OAAO,CAACuC,WAAW,GAAGA,WAAW;EACjCvC,OAAO,CAAC0C,MAAM,GAAGA,MAAM;EACvB1C,OAAO,CAAC8C,QAAQ,GAAGA,QAAQ;EAC3B,OAAO9C,OAAO;AAChB,CAAC;AAEDgD,MAAM,CAACC,OAAO,GAAGrD,SAAS","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}