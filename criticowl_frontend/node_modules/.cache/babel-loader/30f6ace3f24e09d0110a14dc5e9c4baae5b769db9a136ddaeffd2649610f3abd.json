{"ast":null,"code":"//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-nlp”.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar sort4FT = require('./sort4FT.js');\nvar containedMarkings = require('./contained-markings.js');\nvar as = Object.create(null);\n\n// ### array\n/**\n * It is a simple passthru function i.e. input is returned as-is.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {string[]}        the input `tokens` as-is.\n * @private\n */\nas.array = function (tokens) {\n  // Return the input tokens as-is.\n  return tokens;\n}; // array()\n\n// ### set\n/**\n * Constructs set from the `tokens`.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {set}      the set of `tokens`.\n * @private\n */\nas.set = function (tokens) {\n  // Create set & return.\n  return new Set(tokens);\n}; // set()\n\n// ### bow\n/**\n *\n * Constructs the bag of words from the `tokens`.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {objects}         the bag of words object containing `token/frequency`\n *                           `key/value` pairs.\n * @private\n */\nas.bow = function (tokens) {\n  // Bag of words.\n  var bow = Object.create(null);\n  var t;\n  for (let i = 0; i < tokens.length; i += 1) {\n    t = tokens[i];\n    bow[t] = 1 + (bow[t] || 0);\n  }\n  return bow;\n}; // bow()\n\n// ### freqTable\n/**\n * Constructs the frequency table of `tokens`, which sorted in a descending\n * order of token's frequency.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {array[]}         array of `[ token, frequency ]` pairs.\n * @private\n */\nas.freqTable = function (tokens) {\n  // NOTE: build FT based on argument type i.e. array or object (its.detail)\n  var bow = as.bow(tokens);\n  var keys = Object.keys(bow);\n  var length = keys.length;\n  var table = new Array(length);\n  for (var i = 0; i < length; i += 1) {\n    table[i] = [keys[i], bow[keys[i]]];\n  }\n  return table.sort(sort4FT);\n}; // freqTable()\n\n// ### bigrams\n/**\n * Generates bigrams of the input tokens.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {array[]}         array of `[ token`<sub>i</sub>`, token`<sub>i+1</sub> `  ]`\n *                           bigrams.\n * @private\n */\nas.bigrams = function (tokens) {\n  // Bigrams will be stored here.\n  var bgs = [];\n  // Helper variables.\n  var i, imax;\n  // Create bigrams.\n  for (i = 0, imax = tokens.length - 1; i < imax; i += 1) {\n    bgs.push([tokens[i], tokens[i + 1]]);\n  }\n  return bgs;\n}; // bigrams()\n\nas.unique = function (tokens) {\n  return Array.from(new Set(tokens));\n}; // unique()\n\n// ### text\n/**\n *\n * Generates the text by joining the contents of `twps` array (tokens with\n * preceding spaces).\n *\n * @param  {array} twps Array containing tokens with preceding spaces.\n * @return {string}     the text.\n * @private\n*/\nas.text = function (twps) {\n  // Join on empty-space as preceding spaces are part of `twps`!\n  return twps.join('').trim();\n}; // text()\n\n// ### markedUpText\n/**\n *\n * Generates the marked up text of the span specified by the `start` and `end` using\n * `twps` and `markings`.\n *\n * @param  {array}  twps     Array containing tokens with preceding spaces.\n * @param  {object}  rdd     Raw Document Data structure.\n * @param  {number} start    The start index of the tokens.\n * @param  {number} end      The end index of the tokens.\n * @return {string}          the markedup text.\n * @private\n*/\nas.markedUpText = function (twps, rdd, start, end) {\n  // Extract markings.\n  const markings = rdd.markings;\n  // Offset to be added while computing `first` and `last` indexes of `twps`.\n  var offset = start * 2;\n  // Compute the `range` of `markings` to consider on the basis `start` and `end`.\n  var range = containedMarkings(markings, start, end);\n  if (range === null) {\n    // Means no valid range, return the text as is.\n    return twps.join('').trim();\n  }\n  // For every marking prefix the `first` one with `beginMarker` and suffix\n  // the `last` one with `endMarker`.\n  for (let i = range.left; i <= range.right; i += 1) {\n    const first = markings[i][0] * 2 - offset + 1;\n    const last = markings[i][1] * 2 - offset + 1;\n    const beginMarker = markings[i][2] === undefined ? '<mark>' : markings[i][2];\n    const endMarker = markings[i][3] === undefined ? '</mark>' : markings[i][3];\n    twps[first] = beginMarker + twps[first];\n    twps[last] += endMarker;\n  }\n\n  // Join all the elements and return the `markedUpText`.\n  return twps.join('').trim();\n}; // markedUpText()\n\nas.vector = function (tokens, rdd) {\n  if (!rdd.wordVectors) throw Error('wink-nlp: word vectors are not loaded, use const nlp = winkNLP( model, pipe, wordVectors ) to load.');\n\n  // Get size of a vector from word vectors\n  const size = rdd.wordVectors.dimensions;\n  const precision = rdd.wordVectors.precision;\n  const vectors = rdd.wordVectors.vectors;\n  const l2NormIndex = rdd.wordVectors.l2NormIndex;\n\n  // Set up a new initialized vector of `size`\n  const v = new Array(size);\n  v.fill(0);\n  // Compute average.\n  // We will count the number of tokens as some of them may not have a vector.\n  let numOfTokens = 0;\n  for (let i = 0; i < tokens.length; i += 1) {\n    // Extract token vector for the current token.\n    const tv = vectors[tokens[i].toLowerCase()];\n    // Increment `numOfTokens` if the above operation was successful\n    // AND l2Norm is non-zero, because for UNK vectors it is set to 0.\n    // The later is applicable for the contextual vectors, where in event\n    // of UNK, an all zero vectors is set for UNK word.\n    if (tv !== undefined && tv[l2NormIndex] !== 0) numOfTokens += 1;\n    for (let j = 0; j < size; j += 1) {\n      // Keep summing, eventually it will be divided by `numOfTokens` to obtain avareage.\n      v[j] += tv === undefined ? 0 : tv[j];\n    }\n  }\n\n  // if no token's vector is found, return a 0-vector!\n  if (numOfTokens === 0) {\n    // Push l2Norm, which is 0 in this case.\n    v.push(0);\n    return v;\n  }\n\n  // Non-0 vector, find average by dividing the sum by numOfTokens\n  // also compute l2Norm.\n  let l2Norm = 0;\n  for (let i = 0; i < size; i += 1) {\n    v[i] = +(v[i] / numOfTokens).toFixed(precision);\n    l2Norm += v[i] * v[i];\n  }\n  // `l2Norm` becomes the `size+1th` element for faster cosine similarity/normalization.\n  v.push(+Math.sqrt(l2Norm).toFixed(precision));\n  return v;\n}; // vector()\n\nmodule.exports = as;","map":{"version":3,"names":["sort4FT","require","containedMarkings","as","Object","create","array","tokens","set","Set","bow","t","i","length","freqTable","keys","table","Array","sort","bigrams","bgs","imax","push","unique","from","text","twps","join","trim","markedUpText","rdd","start","end","markings","offset","range","left","right","first","last","beginMarker","undefined","endMarker","vector","wordVectors","Error","size","dimensions","precision","vectors","l2NormIndex","v","fill","numOfTokens","tv","toLowerCase","j","l2Norm","toFixed","Math","sqrt","module","exports"],"sources":["C:/Users/cheko/Desktop/Education/Freelance/criticowl-main/criticowl_frontend/node_modules/wink-nlp/src/as.js"],"sourcesContent":["//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-nlp”.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar sort4FT = require( './sort4FT.js' );\nvar containedMarkings = require( './contained-markings.js' );\nvar as = Object.create( null );\n\n// ### array\n/**\n * It is a simple passthru function i.e. input is returned as-is.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {string[]}        the input `tokens` as-is.\n * @private\n */\nas.array = function ( tokens ) {\n  // Return the input tokens as-is.\n  return tokens;\n}; // array()\n\n// ### set\n/**\n * Constructs set from the `tokens`.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {set}      the set of `tokens`.\n * @private\n */\nas.set = function ( tokens ) {\n  // Create set & return.\n  return new Set( tokens );\n}; // set()\n\n// ### bow\n/**\n *\n * Constructs the bag of words from the `tokens`.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {objects}         the bag of words object containing `token/frequency`\n *                           `key/value` pairs.\n * @private\n */\nas.bow = function ( tokens ) {\n  // Bag of words.\n  var bow = Object.create( null );\n  var t;\n  for ( let i = 0; i < tokens.length; i += 1 ) {\n    t = tokens[ i ];\n    bow[ t ] = 1 + ( bow[ t ] || 0 );\n  }\n\n  return bow;\n}; // bow()\n\n// ### freqTable\n/**\n * Constructs the frequency table of `tokens`, which sorted in a descending\n * order of token's frequency.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {array[]}         array of `[ token, frequency ]` pairs.\n * @private\n */\nas.freqTable = function ( tokens ) {\n  // NOTE: build FT based on argument type i.e. array or object (its.detail)\n  var bow = as.bow( tokens );\n  var keys = Object.keys( bow );\n  var length = keys.length;\n  var table = new Array( length );\n\n  for ( var i = 0; i < length; i += 1 ) {\n    table[ i ] = [ keys[ i ], bow[ keys[ i ] ] ];\n  }\n\n  return table.sort( sort4FT );\n}; // freqTable()\n\n// ### bigrams\n/**\n * Generates bigrams of the input tokens.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {array[]}         array of `[ token`<sub>i</sub>`, token`<sub>i+1</sub> `  ]`\n *                           bigrams.\n * @private\n */\nas.bigrams = function ( tokens ) {\n  // Bigrams will be stored here.\n  var bgs = [];\n  // Helper variables.\n  var i, imax;\n  // Create bigrams.\n  for ( i = 0, imax = tokens.length - 1; i < imax; i += 1 ) {\n    bgs.push( [ tokens[ i ], tokens[ i + 1 ] ] );\n  }\n  return bgs;\n}; // bigrams()\n\nas.unique = function ( tokens ) {\n  return Array.from( new Set( tokens ) );\n}; // unique()\n\n// ### text\n/**\n *\n * Generates the text by joining the contents of `twps` array (tokens with\n * preceding spaces).\n *\n * @param  {array} twps Array containing tokens with preceding spaces.\n * @return {string}     the text.\n * @private\n*/\nas.text = function ( twps ) {\n  // Join on empty-space as preceding spaces are part of `twps`!\n  return twps.join( '' ).trim();\n}; // text()\n\n// ### markedUpText\n/**\n *\n * Generates the marked up text of the span specified by the `start` and `end` using\n * `twps` and `markings`.\n *\n * @param  {array}  twps     Array containing tokens with preceding spaces.\n * @param  {object}  rdd     Raw Document Data structure.\n * @param  {number} start    The start index of the tokens.\n * @param  {number} end      The end index of the tokens.\n * @return {string}          the markedup text.\n * @private\n*/\nas.markedUpText = function ( twps, rdd, start, end ) {\n  // Extract markings.\n  const markings = rdd.markings;\n  // Offset to be added while computing `first` and `last` indexes of `twps`.\n  var offset = start * 2;\n  // Compute the `range` of `markings` to consider on the basis `start` and `end`.\n  var range = containedMarkings( markings, start, end );\n  if ( range === null ) {\n    // Means no valid range, return the text as is.\n    return twps.join( '' ).trim();\n  }\n  // For every marking prefix the `first` one with `beginMarker` and suffix\n  // the `last` one with `endMarker`.\n  for ( let i = range.left; i <= range.right; i += 1 ) {\n    const first = ( ( markings[ i ][ 0 ] * 2 ) - offset ) + 1;\n    const last  = ( ( markings[ i ][ 1 ] * 2 ) - offset ) + 1;\n    const beginMarker = ( markings[ i ][ 2 ]  === undefined ) ? '<mark>' : markings[ i ][ 2 ];\n    const endMarker = ( markings[ i ][ 3 ]  === undefined ) ? '</mark>' : markings[ i ][ 3 ];\n\n    twps[ first ] = beginMarker + twps[ first ];\n    twps[ last ] += endMarker;\n  }\n\n  // Join all the elements and return the `markedUpText`.\n  return twps.join( '' ).trim();\n}; // markedUpText()\n\nas.vector = function ( tokens, rdd ) {\n  if ( !rdd.wordVectors )\n    throw Error( 'wink-nlp: word vectors are not loaded, use const nlp = winkNLP( model, pipe, wordVectors ) to load.' );\n\n  // Get size of a vector from word vectors\n  const size = rdd.wordVectors.dimensions;\n  const precision = rdd.wordVectors.precision;\n  const vectors = rdd.wordVectors.vectors;\n  const l2NormIndex = rdd.wordVectors.l2NormIndex;\n\n  // Set up a new initialized vector of `size`\n  const v = new Array( size );\n  v.fill( 0 );\n  // Compute average.\n  // We will count the number of tokens as some of them may not have a vector.\n  let numOfTokens = 0;\n  for ( let i = 0; i < tokens.length; i += 1 ) {\n    // Extract token vector for the current token.\n    const tv = vectors[ tokens[ i ].toLowerCase() ];\n    // Increment `numOfTokens` if the above operation was successful\n    // AND l2Norm is non-zero, because for UNK vectors it is set to 0.\n    // The later is applicable for the contextual vectors, where in event\n    // of UNK, an all zero vectors is set for UNK word.\n    if ( tv !== undefined && tv[ l2NormIndex ] !== 0 ) numOfTokens += 1;\n    for ( let j = 0; j < size; j += 1 ) {\n      // Keep summing, eventually it will be divided by `numOfTokens` to obtain avareage.\n      v[ j ] += ( tv === undefined ) ? 0 : tv[ j ];\n    }\n  }\n\n  // if no token's vector is found, return a 0-vector!\n  if ( numOfTokens === 0 ) {\n    // Push l2Norm, which is 0 in this case.\n    v.push( 0 );\n    return v;\n  }\n\n  // Non-0 vector, find average by dividing the sum by numOfTokens\n  // also compute l2Norm.\n  let l2Norm = 0;\n  for ( let i = 0; i < size; i += 1 ) {\n    v[ i ] = +( v[ i ] / numOfTokens ).toFixed( precision );\n    l2Norm += v[ i ] * v[ i ];\n  }\n  // `l2Norm` becomes the `size+1th` element for faster cosine similarity/normalization.\n  v.push( +( Math.sqrt( l2Norm ).toFixed( precision ) ) );\n\n  return v;\n}; // vector()\n\nmodule.exports = as;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,IAAIA,OAAO,GAAGC,OAAO,CAAE,cAAe,CAAC;AACvC,IAAIC,iBAAiB,GAAGD,OAAO,CAAE,yBAA0B,CAAC;AAC5D,IAAIE,EAAE,GAAGC,MAAM,CAACC,MAAM,CAAE,IAAK,CAAC;;AAE9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAF,EAAE,CAACG,KAAK,GAAG,UAAWC,MAAM,EAAG;EAC7B;EACA,OAAOA,MAAM;AACf,CAAC,CAAC,CAAC;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAJ,EAAE,CAACK,GAAG,GAAG,UAAWD,MAAM,EAAG;EAC3B;EACA,OAAO,IAAIE,GAAG,CAAEF,MAAO,CAAC;AAC1B,CAAC,CAAC,CAAC;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAJ,EAAE,CAACO,GAAG,GAAG,UAAWH,MAAM,EAAG;EAC3B;EACA,IAAIG,GAAG,GAAGN,MAAM,CAACC,MAAM,CAAE,IAAK,CAAC;EAC/B,IAAIM,CAAC;EACL,KAAM,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,MAAM,CAACM,MAAM,EAAED,CAAC,IAAI,CAAC,EAAG;IAC3CD,CAAC,GAAGJ,MAAM,CAAEK,CAAC,CAAE;IACfF,GAAG,CAAEC,CAAC,CAAE,GAAG,CAAC,IAAKD,GAAG,CAAEC,CAAC,CAAE,IAAI,CAAC,CAAE;EAClC;EAEA,OAAOD,GAAG;AACZ,CAAC,CAAC,CAAC;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAP,EAAE,CAACW,SAAS,GAAG,UAAWP,MAAM,EAAG;EACjC;EACA,IAAIG,GAAG,GAAGP,EAAE,CAACO,GAAG,CAAEH,MAAO,CAAC;EAC1B,IAAIQ,IAAI,GAAGX,MAAM,CAACW,IAAI,CAAEL,GAAI,CAAC;EAC7B,IAAIG,MAAM,GAAGE,IAAI,CAACF,MAAM;EACxB,IAAIG,KAAK,GAAG,IAAIC,KAAK,CAAEJ,MAAO,CAAC;EAE/B,KAAM,IAAID,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGC,MAAM,EAAED,CAAC,IAAI,CAAC,EAAG;IACpCI,KAAK,CAAEJ,CAAC,CAAE,GAAG,CAAEG,IAAI,CAAEH,CAAC,CAAE,EAAEF,GAAG,CAAEK,IAAI,CAAEH,CAAC,CAAE,CAAE,CAAE;EAC9C;EAEA,OAAOI,KAAK,CAACE,IAAI,CAAElB,OAAQ,CAAC;AAC9B,CAAC,CAAC,CAAC;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAG,EAAE,CAACgB,OAAO,GAAG,UAAWZ,MAAM,EAAG;EAC/B;EACA,IAAIa,GAAG,GAAG,EAAE;EACZ;EACA,IAAIR,CAAC,EAAES,IAAI;EACX;EACA,KAAMT,CAAC,GAAG,CAAC,EAAES,IAAI,GAAGd,MAAM,CAACM,MAAM,GAAG,CAAC,EAAED,CAAC,GAAGS,IAAI,EAAET,CAAC,IAAI,CAAC,EAAG;IACxDQ,GAAG,CAACE,IAAI,CAAE,CAAEf,MAAM,CAAEK,CAAC,CAAE,EAAEL,MAAM,CAAEK,CAAC,GAAG,CAAC,CAAE,CAAG,CAAC;EAC9C;EACA,OAAOQ,GAAG;AACZ,CAAC,CAAC,CAAC;;AAEHjB,EAAE,CAACoB,MAAM,GAAG,UAAWhB,MAAM,EAAG;EAC9B,OAAOU,KAAK,CAACO,IAAI,CAAE,IAAIf,GAAG,CAAEF,MAAO,CAAE,CAAC;AACxC,CAAC,CAAC,CAAC;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAJ,EAAE,CAACsB,IAAI,GAAG,UAAWC,IAAI,EAAG;EAC1B;EACA,OAAOA,IAAI,CAACC,IAAI,CAAE,EAAG,CAAC,CAACC,IAAI,CAAC,CAAC;AAC/B,CAAC,CAAC,CAAC;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAzB,EAAE,CAAC0B,YAAY,GAAG,UAAWH,IAAI,EAAEI,GAAG,EAAEC,KAAK,EAAEC,GAAG,EAAG;EACnD;EACA,MAAMC,QAAQ,GAAGH,GAAG,CAACG,QAAQ;EAC7B;EACA,IAAIC,MAAM,GAAGH,KAAK,GAAG,CAAC;EACtB;EACA,IAAII,KAAK,GAAGjC,iBAAiB,CAAE+B,QAAQ,EAAEF,KAAK,EAAEC,GAAI,CAAC;EACrD,IAAKG,KAAK,KAAK,IAAI,EAAG;IACpB;IACA,OAAOT,IAAI,CAACC,IAAI,CAAE,EAAG,CAAC,CAACC,IAAI,CAAC,CAAC;EAC/B;EACA;EACA;EACA,KAAM,IAAIhB,CAAC,GAAGuB,KAAK,CAACC,IAAI,EAAExB,CAAC,IAAIuB,KAAK,CAACE,KAAK,EAAEzB,CAAC,IAAI,CAAC,EAAG;IACnD,MAAM0B,KAAK,GAAOL,QAAQ,CAAErB,CAAC,CAAE,CAAE,CAAC,CAAE,GAAG,CAAC,GAAKsB,MAAM,GAAK,CAAC;IACzD,MAAMK,IAAI,GAAQN,QAAQ,CAAErB,CAAC,CAAE,CAAE,CAAC,CAAE,GAAG,CAAC,GAAKsB,MAAM,GAAK,CAAC;IACzD,MAAMM,WAAW,GAAKP,QAAQ,CAAErB,CAAC,CAAE,CAAE,CAAC,CAAE,KAAM6B,SAAS,GAAK,QAAQ,GAAGR,QAAQ,CAAErB,CAAC,CAAE,CAAE,CAAC,CAAE;IACzF,MAAM8B,SAAS,GAAKT,QAAQ,CAAErB,CAAC,CAAE,CAAE,CAAC,CAAE,KAAM6B,SAAS,GAAK,SAAS,GAAGR,QAAQ,CAAErB,CAAC,CAAE,CAAE,CAAC,CAAE;IAExFc,IAAI,CAAEY,KAAK,CAAE,GAAGE,WAAW,GAAGd,IAAI,CAAEY,KAAK,CAAE;IAC3CZ,IAAI,CAAEa,IAAI,CAAE,IAAIG,SAAS;EAC3B;;EAEA;EACA,OAAOhB,IAAI,CAACC,IAAI,CAAE,EAAG,CAAC,CAACC,IAAI,CAAC,CAAC;AAC/B,CAAC,CAAC,CAAC;;AAEHzB,EAAE,CAACwC,MAAM,GAAG,UAAWpC,MAAM,EAAEuB,GAAG,EAAG;EACnC,IAAK,CAACA,GAAG,CAACc,WAAW,EACnB,MAAMC,KAAK,CAAE,qGAAsG,CAAC;;EAEtH;EACA,MAAMC,IAAI,GAAGhB,GAAG,CAACc,WAAW,CAACG,UAAU;EACvC,MAAMC,SAAS,GAAGlB,GAAG,CAACc,WAAW,CAACI,SAAS;EAC3C,MAAMC,OAAO,GAAGnB,GAAG,CAACc,WAAW,CAACK,OAAO;EACvC,MAAMC,WAAW,GAAGpB,GAAG,CAACc,WAAW,CAACM,WAAW;;EAE/C;EACA,MAAMC,CAAC,GAAG,IAAIlC,KAAK,CAAE6B,IAAK,CAAC;EAC3BK,CAAC,CAACC,IAAI,CAAE,CAAE,CAAC;EACX;EACA;EACA,IAAIC,WAAW,GAAG,CAAC;EACnB,KAAM,IAAIzC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,MAAM,CAACM,MAAM,EAAED,CAAC,IAAI,CAAC,EAAG;IAC3C;IACA,MAAM0C,EAAE,GAAGL,OAAO,CAAE1C,MAAM,CAAEK,CAAC,CAAE,CAAC2C,WAAW,CAAC,CAAC,CAAE;IAC/C;IACA;IACA;IACA;IACA,IAAKD,EAAE,KAAKb,SAAS,IAAIa,EAAE,CAAEJ,WAAW,CAAE,KAAK,CAAC,EAAGG,WAAW,IAAI,CAAC;IACnE,KAAM,IAAIG,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGV,IAAI,EAAEU,CAAC,IAAI,CAAC,EAAG;MAClC;MACAL,CAAC,CAAEK,CAAC,CAAE,IAAMF,EAAE,KAAKb,SAAS,GAAK,CAAC,GAAGa,EAAE,CAAEE,CAAC,CAAE;IAC9C;EACF;;EAEA;EACA,IAAKH,WAAW,KAAK,CAAC,EAAG;IACvB;IACAF,CAAC,CAAC7B,IAAI,CAAE,CAAE,CAAC;IACX,OAAO6B,CAAC;EACV;;EAEA;EACA;EACA,IAAIM,MAAM,GAAG,CAAC;EACd,KAAM,IAAI7C,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGkC,IAAI,EAAElC,CAAC,IAAI,CAAC,EAAG;IAClCuC,CAAC,CAAEvC,CAAC,CAAE,GAAG,CAAC,CAAEuC,CAAC,CAAEvC,CAAC,CAAE,GAAGyC,WAAW,EAAGK,OAAO,CAAEV,SAAU,CAAC;IACvDS,MAAM,IAAIN,CAAC,CAAEvC,CAAC,CAAE,GAAGuC,CAAC,CAAEvC,CAAC,CAAE;EAC3B;EACA;EACAuC,CAAC,CAAC7B,IAAI,CAAE,CAAGqC,IAAI,CAACC,IAAI,CAAEH,MAAO,CAAC,CAACC,OAAO,CAAEV,SAAU,CAAI,CAAC;EAEvD,OAAOG,CAAC;AACV,CAAC,CAAC,CAAC;;AAEHU,MAAM,CAACC,OAAO,GAAG3D,EAAE","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}