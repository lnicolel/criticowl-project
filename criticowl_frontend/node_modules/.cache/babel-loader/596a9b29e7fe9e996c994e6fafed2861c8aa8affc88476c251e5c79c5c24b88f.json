{"ast":null,"code":"//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-nlp”.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar constants = require('./constants.js');\n// Size of a single token.\nvar tkSize = constants.tkSize;\n// Bits reserved for `lemma`.\nvar bits4lemma = constants.bits4lemma;\n// Mask for extracting pos\nvar posMask = constants.posMask;\nvar mappers = Object.create(null);\n\n// ## mapRawTokens2UIDn\n/**\n * Maps the raw tokens to an array of uid of normal of tokens.\n * @private\n *\n * @param {object} rdd The raw document data-structure.\n * @returns {array} conatining the uid of normals.\n * @private\n*/\nvar mapRawTokens2UIdOfNormal = function (rdd) {\n  // Extract tokens & cache.\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  // Will contain only the hash of normal of tokenized lexemes.\n  var mappedTokens = new Array(rdd.numOfTokens);\n  var i, k;\n  for (i = 0; i < tokens.length; i += tkSize) {\n    k = i + 1;\n    mappedTokens[i / tkSize] = tokens[k] > 65535 ?\n    // Handle contraction's expansion.\n    cache.nox(tokens[k]) :\n    // Handle all other words.\n    cache.normal(tokens[i]);\n  } // for ( i = 0; i < tokens.length...\n\n  return mappedTokens;\n}; // mapRawTokens2UIdOfNormal()\n\n// ## mapRawTokens2UIDn\n/**\n * Maps the raw tokens to an array of uid of value of tokens.\n * @private\n *\n * @param {object} rdd The raw document data-structure.\n * @returns {array} conatining the uid of values.\n * @private\n*/\nvar mapRawTokens2UIdOfValue = function (rdd) {\n  // Extract tokens.\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  // Will contain only the hash of value of tokenized lexemes.\n  var mappedTokens = new Array(rdd.numOfTokens);\n  var i;\n  for (i = 0; i < tokens.length; i += tkSize) {\n    // Use mapped spelling — this ensure correct pos tagging & lemmatization etc.\n    // as mapped spelling is the gold spelling.\n    mappedTokens[i / tkSize] = cache.mappedSpelling(tokens[i]);\n  } // for ( i = 0; i < tokens.length...\n  return mappedTokens;\n}; // mapRawTokens2UIdOfValue()\n\n// ## mapRawTokens2UIdOfPOS\n/**\n * Extracts the default or most likely pos tag for every token.\n * @private\n *\n * @param {object} rdd the raw document data.\n * @returns {array} conatining the default pos tags.\n * @private\n*/\nvar mapRawTokens2UIdOfDefaultPOS = function (rdd) {\n  // Extract tokens & cache.\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  var posTags = new Array(rdd.numOfTokens);\n  let pk = 0;\n  for (let i = 0; i < tokens.length; i += tkSize, pk += 1) {\n    posTags[pk] = tokens[i + 2] === 0 ?\n    // Make UNK to NOUN to handle the remote possibility of ML POS being undefined!\n    // Also use mapped spelling — this ensure correct pos tagging & lemmatization etc.\n    // as mapped spelling is the gold spelling.\n    cache.posOf(cache.mappedSpelling(tokens[i])) || 8 : (tokens[i + 2] & posMask) >>> bits4lemma; // eslint-disable-line no-bitwise\n  }\n  return posTags;\n}; // mapRawTokens2UIdOfDefaultPOS()\n\nmappers.mapRawTokens2UIdOfNormal = mapRawTokens2UIdOfNormal;\nmappers.mapRawTokens2UIdOfValue = mapRawTokens2UIdOfValue;\nmappers.mapRawTokens2UIdOfDefaultPOS = mapRawTokens2UIdOfDefaultPOS;\nmodule.exports = mappers;","map":{"version":3,"names":["constants","require","tkSize","bits4lemma","posMask","mappers","Object","create","mapRawTokens2UIdOfNormal","rdd","tokens","cache","mappedTokens","Array","numOfTokens","i","k","length","nox","normal","mapRawTokens2UIdOfValue","mappedSpelling","mapRawTokens2UIdOfDefaultPOS","posTags","pk","posOf","module","exports"],"sources":["C:/Users/cheko/Desktop/Education/Freelance/criticowl-main/criticowl_frontend/node_modules/wink-nlp/src/tokens-mappers.js"],"sourcesContent":["//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-nlp”.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar constants = require( './constants.js' );\n// Size of a single token.\nvar tkSize = constants.tkSize;\n// Bits reserved for `lemma`.\nvar bits4lemma = constants.bits4lemma;\n// Mask for extracting pos\nvar posMask = constants.posMask;\n\nvar mappers = Object.create( null );\n\n// ## mapRawTokens2UIDn\n/**\n * Maps the raw tokens to an array of uid of normal of tokens.\n * @private\n *\n * @param {object} rdd The raw document data-structure.\n * @returns {array} conatining the uid of normals.\n * @private\n*/\nvar mapRawTokens2UIdOfNormal = function ( rdd ) {\n  // Extract tokens & cache.\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  // Will contain only the hash of normal of tokenized lexemes.\n  var mappedTokens = new Array( rdd.numOfTokens );\n  var i, k;\n  for ( i = 0; i < tokens.length; i += tkSize ) {\n    k = i + 1;\n    mappedTokens[ i / tkSize ] = ( tokens[ k ] > 65535 ) ?\n                              // Handle contraction's expansion.\n                              cache.nox( tokens[ k ] ) :\n                              // Handle all other words.\n                              cache.normal( tokens[ i ] );\n  } // for ( i = 0; i < tokens.length...\n\n  return mappedTokens;\n}; // mapRawTokens2UIdOfNormal()\n\n// ## mapRawTokens2UIDn\n/**\n * Maps the raw tokens to an array of uid of value of tokens.\n * @private\n *\n * @param {object} rdd The raw document data-structure.\n * @returns {array} conatining the uid of values.\n * @private\n*/\nvar mapRawTokens2UIdOfValue = function ( rdd ) {\n  // Extract tokens.\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  // Will contain only the hash of value of tokenized lexemes.\n  var mappedTokens = new Array( rdd.numOfTokens );\n  var i;\n  for ( i = 0; i < tokens.length; i += tkSize ) {\n    // Use mapped spelling — this ensure correct pos tagging & lemmatization etc.\n    // as mapped spelling is the gold spelling.\n    mappedTokens[ i / tkSize ] = cache.mappedSpelling( tokens[ i ] );\n  } // for ( i = 0; i < tokens.length...\n  return mappedTokens;\n}; // mapRawTokens2UIdOfValue()\n\n// ## mapRawTokens2UIdOfPOS\n/**\n * Extracts the default or most likely pos tag for every token.\n * @private\n *\n * @param {object} rdd the raw document data.\n * @returns {array} conatining the default pos tags.\n * @private\n*/\nvar mapRawTokens2UIdOfDefaultPOS = function ( rdd ) {\n  // Extract tokens & cache.\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  var posTags = new Array( rdd.numOfTokens );\n  let pk = 0;\n  for ( let i = 0; i < tokens.length; i += tkSize, pk += 1 ) {\n    posTags[ pk ] = ( tokens[ ( i ) + 2 ] === 0 ) ?\n                      // Make UNK to NOUN to handle the remote possibility of ML POS being undefined!\n                      // Also use mapped spelling — this ensure correct pos tagging & lemmatization etc.\n                      // as mapped spelling is the gold spelling.\n                      ( cache.posOf( cache.mappedSpelling( tokens[ i ] ) ) || 8 ) :\n                      ( ( tokens[ ( i ) + 2 ] & posMask ) >>> bits4lemma ); // eslint-disable-line no-bitwise\n  }\n  return posTags;\n}; // mapRawTokens2UIdOfDefaultPOS()\n\nmappers.mapRawTokens2UIdOfNormal = mapRawTokens2UIdOfNormal;\nmappers.mapRawTokens2UIdOfValue = mapRawTokens2UIdOfValue;\nmappers.mapRawTokens2UIdOfDefaultPOS = mapRawTokens2UIdOfDefaultPOS;\n\nmodule.exports = mappers;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,IAAIA,SAAS,GAAGC,OAAO,CAAE,gBAAiB,CAAC;AAC3C;AACA,IAAIC,MAAM,GAAGF,SAAS,CAACE,MAAM;AAC7B;AACA,IAAIC,UAAU,GAAGH,SAAS,CAACG,UAAU;AACrC;AACA,IAAIC,OAAO,GAAGJ,SAAS,CAACI,OAAO;AAE/B,IAAIC,OAAO,GAAGC,MAAM,CAACC,MAAM,CAAE,IAAK,CAAC;;AAEnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIC,wBAAwB,GAAG,SAAAA,CAAWC,GAAG,EAAG;EAC9C;EACA,IAAIC,MAAM,GAAGD,GAAG,CAACC,MAAM;EACvB,IAAIC,KAAK,GAAGF,GAAG,CAACE,KAAK;EACrB;EACA,IAAIC,YAAY,GAAG,IAAIC,KAAK,CAAEJ,GAAG,CAACK,WAAY,CAAC;EAC/C,IAAIC,CAAC,EAAEC,CAAC;EACR,KAAMD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,MAAM,CAACO,MAAM,EAAEF,CAAC,IAAIb,MAAM,EAAG;IAC5Cc,CAAC,GAAGD,CAAC,GAAG,CAAC;IACTH,YAAY,CAAEG,CAAC,GAAGb,MAAM,CAAE,GAAKQ,MAAM,CAAEM,CAAC,CAAE,GAAG,KAAK;IACxB;IACAL,KAAK,CAACO,GAAG,CAAER,MAAM,CAAEM,CAAC,CAAG,CAAC;IACxB;IACAL,KAAK,CAACQ,MAAM,CAAET,MAAM,CAAEK,CAAC,CAAG,CAAC;EACvD,CAAC,CAAC;;EAEF,OAAOH,YAAY;AACrB,CAAC,CAAC,CAAC;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIQ,uBAAuB,GAAG,SAAAA,CAAWX,GAAG,EAAG;EAC7C;EACA,IAAIC,MAAM,GAAGD,GAAG,CAACC,MAAM;EACvB,IAAIC,KAAK,GAAGF,GAAG,CAACE,KAAK;EACrB;EACA,IAAIC,YAAY,GAAG,IAAIC,KAAK,CAAEJ,GAAG,CAACK,WAAY,CAAC;EAC/C,IAAIC,CAAC;EACL,KAAMA,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,MAAM,CAACO,MAAM,EAAEF,CAAC,IAAIb,MAAM,EAAG;IAC5C;IACA;IACAU,YAAY,CAAEG,CAAC,GAAGb,MAAM,CAAE,GAAGS,KAAK,CAACU,cAAc,CAAEX,MAAM,CAAEK,CAAC,CAAG,CAAC;EAClE,CAAC,CAAC;EACF,OAAOH,YAAY;AACrB,CAAC,CAAC,CAAC;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIU,4BAA4B,GAAG,SAAAA,CAAWb,GAAG,EAAG;EAClD;EACA,IAAIC,MAAM,GAAGD,GAAG,CAACC,MAAM;EACvB,IAAIC,KAAK,GAAGF,GAAG,CAACE,KAAK;EACrB,IAAIY,OAAO,GAAG,IAAIV,KAAK,CAAEJ,GAAG,CAACK,WAAY,CAAC;EAC1C,IAAIU,EAAE,GAAG,CAAC;EACV,KAAM,IAAIT,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,MAAM,CAACO,MAAM,EAAEF,CAAC,IAAIb,MAAM,EAAEsB,EAAE,IAAI,CAAC,EAAG;IACzDD,OAAO,CAAEC,EAAE,CAAE,GAAKd,MAAM,CAAIK,CAAC,GAAK,CAAC,CAAE,KAAK,CAAC;IACzB;IACA;IACA;IACEJ,KAAK,CAACc,KAAK,CAAEd,KAAK,CAACU,cAAc,CAAEX,MAAM,CAAEK,CAAC,CAAG,CAAE,CAAC,IAAI,CAAC,GACvD,CAAEL,MAAM,CAAIK,CAAC,GAAK,CAAC,CAAE,GAAGX,OAAO,MAAOD,UAAY,CAAC,CAAC;EAC1E;EACA,OAAOoB,OAAO;AAChB,CAAC,CAAC,CAAC;;AAEHlB,OAAO,CAACG,wBAAwB,GAAGA,wBAAwB;AAC3DH,OAAO,CAACe,uBAAuB,GAAGA,uBAAuB;AACzDf,OAAO,CAACiB,4BAA4B,GAAGA,4BAA4B;AAEnEI,MAAM,CAACC,OAAO,GAAGtB,OAAO","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}