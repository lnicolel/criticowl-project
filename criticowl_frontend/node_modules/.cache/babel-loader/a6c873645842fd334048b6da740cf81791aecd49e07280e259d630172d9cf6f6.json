{"ast":null,"code":"//     wink-pos-tagger\n//     English Part-of-speech (POS) tagger\n//\n//     Copyright (C) 2017-19  GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-pos-tagger”.\n//\n//     Permission is hereby granted, free of charge, to any person obtaining a\n//     copy of this software and associated documentation files (the \"Software\"),\n//     to deal in the Software without restriction, including without limitation\n//     the rights to use, copy, modify, merge, publish, distribute, sublicense,\n//     and/or sell copies of the Software, and to permit persons to whom the\n//     Software is furnished to do so, subject to the following conditions:\n//\n//     The above copyright notice and this permission notice shall be included\n//     in all copies or substantial portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\nvar helpers = require('wink-helpers');\nvar winkLexicon = require('wink-lexicon/src/lexicon.js');\nvar unigramPOSTagger = require('./unigram-tagger.js');\nvar applyContextRules = require('./rules-engine.js');\nvar wl = require('wink-lemmatizer');\nvar lemmatizeVBX = wl.lemmatizeVerb;\nvar lemmatizeNNX = wl.lemmatizeNoun;\nvar lemmatizeJJX = wl.lemmatizeAdjective;\n// Load tokenizer, instanciate and get tokenize method; use default config.\nvar tokenize = require('wink-tokenizer')().tokenize;\n// Extract string normalization function from `wink-helpers`.\nvar normalize = helpers.string.normalize;\nvar lemmaExceptions = Object.create(null);\nlemmaExceptions.ai = 'be';\nlemmaExceptions.ca = 'can';\nlemmaExceptions.sha = 'shall';\nlemmaExceptions['\\'ll'] = lemmaExceptions.wo = 'will';\nlemmaExceptions['\\'ve'] = 'have';\nlemmaExceptions['\\'m'] = 'am';\nlemmaExceptions['\\'re'] = 'be';\nlemmaExceptions['n\\'t'] = 'not';\nlemmaExceptions['\\'d'] = 'would';\n// Needed for simple NNP transformation rule.\nconst capA = 'A';\nconst capZ = 'Z';\n// Required in raw tokens tagging\nconst rgxNumber = /^\\d+\\/\\d+|\\d(?:[\\.\\,\\-\\/]?\\d)*(?:\\.\\d+)?$/;\nconst rgxPunctuation = /^[\\’\\'\\‘\\’\\`\\“\\”\\\"\\[\\]\\(\\)\\{\\}\\…\\,\\.\\!\\;\\?\\-\\:]+$/;\n// Used in tagging years.\nconst year = Object.create(null);\nyear['1990s'] = 'CD';\nyear['1980s'] = 'CD';\nyear['1970s'] = 'CD';\nyear['1960s'] = 'CD';\nyear['1950s'] = 'CD';\nyear['1940s'] = 'CD';\nyear['1930s'] = 'CD';\nyear['1910s'] = 'CD';\nyear['mid-1990s'] = 'CD';\nyear['mid-1980s'] = 'CD';\nyear['mid-1970s'] = 'CD';\nyear['mid-1960s'] = 'CD';\nyear['mid-1950s'] = 'CD';\nyear['mid-1940s'] = 'CD';\nyear['mid-1930s'] = 'CD';\nyear['mid-1920s'] = 'CD';\nyear['mid-1910s'] = 'CD';\n\n// ### posTagger\n/**\n *\n * Creates an instance of {@link Tagger}.\n *\n * @return {Tagger} object conatining set of API methods for pos-tagging.\n * @example\n * // Load wink tokenizer.\n * var tagger = require( 'wink-pos-tagger' );\n * // Create your instance of wink tokenizer.\n * var myTagger = posTagger();\n*/\nvar posTagger = function () {\n  /**\n  * @classdesc Tagger class\n  * @class Tagger\n  * @hideconstructor\n  */\n  var methods = Object.create(null);\n\n  // ### updateLexicon\n  /**\n   *\n   * Updates the internal lexicon using the input `lexicon`. If a word/pos pair\n   * is found in the internal lexicon then it's value is updated with the new pos;\n   * otherwise it added.\n   *\n   * @method Tagger#updateLexicon\n   * @param {object} lexicon containing **`word/pos`** pairs to be added to or\n   * replaced in the existing lexicon. The `pos` should be an array containing\n   * pos tags, with the first one as the most frequently used POS. The `word` is\n   * normalized before updating the internal lexicon.\n   * @return {undefined} Nothing!\n   * @throws {Error} if `lexicon` is not a valid JS object.\n   * @example\n   * myTagger.updateLexicon( { Obama: [ 'NNP' ] } );\n  */\n  var updateLexicon = function (lexicon) {\n    if (!helpers.validate.isObject(lexicon)) {\n      throw Error('wink-pos-tagger/updateLexicon: lexicon must be an object, instead found: ' + JSON.stringify(lexicon));\n    }\n    // Update winkLexicon but with **normalized** key.\n    for (var key in lexicon) winkLexicon[normalize(key)] = lexicon[key]; // eslint-disable-line guard-for-in\n  }; // updateLexicon()\n\n  // ### defineConfig\n  /**\n   *\n   * This API has no effect. It has been maintained for compatibility purpose.\n   * The `wink-tokenizer` will now always add **lemma** and **normal** forms.\n   * Note, lemmas are added only for **nouns** (excluding proper noun), **verbs** and\n   * **adjectives**.\n   *\n   * @method Tagger#defineConfig\n   * @return {object} always as `{ lemma: true, normal: true }`.\n   * @example\n   * // There will not be any effect:\n   * var myTagger.defineConfig( { lemma: false } );\n   * // -> { lemma: true, normal: true }\n  */\n  var defineConfig = function () {\n    // Return a copy of configuration object.\n    return JSON.parse(JSON.stringify({\n      lemma: true,\n      normal: true\n    }));\n  }; // defineConfig()\n\n  // ### lemmatize\n  /**\n   *\n   * Performs lemmatization; also applies NNP transformation rules for captitalized\n   * nouns and adjectives and CD rule for years.\n   *\n   * @method Tagger#lemmatize\n   * @param {object[]} tokens to be lemmatized.\n   * @return {object[]} lemmatized tokens.\n   * @private\n  */\n  var lemmatize = function (tokens) {\n    var t, v0, w;\n    var lemma;\n    var tpos;\n    for (let i = 0, imax = tokens.length; i < imax; i += 1) {\n      t = tokens[i];\n      w = t.normal;\n      v0 = t.value[0];\n      tpos = year[w];\n      if (tpos) t.pos = 'CD';\n      // First handle exceptions arising out of contractions.\n      lemma = lemmaExceptions[w];\n      if (lemma) {\n        t.lemma = lemma;\n      } else {\n        // Otherwise use lemmatizer.\n        switch (t.pos[0]) {\n          case 'J':\n            if (v0 >= capA && v0 <= capZ) {\n              t.lemma = w;\n              t.pos = 'NNP';\n            } else {\n              t.lemma = t.pos.length > 2 ? lemmatizeJJX(w) : w;\n            }\n            break;\n          case 'V':\n            t.lemma = t.pos.length > 2 ? t.normal === '\\'s' ? 'be' : lemmatizeVBX(w) : w;\n            break;\n          case 'N':\n            if (v0 >= capA && v0 <= capZ) {\n              t.lemma = w;\n              t.pos = 'NNP';\n            } else {\n              // No lemmatization of NNPs please!\n              t.lemma = t.pos !== 'NNP' && t.pos.length > 2 ? lemmatizeNNX(w) : w;\n            }\n            break;\n          case 'M':\n            t.lemma = lemmatizeVBX(w);\n            break;\n          default:\n          // Do nothing!\n        } // swtich\n      } // if\n    }\n    return tokens;\n  }; // lemmatize()\n\n  // ### tag\n  /**\n   *\n   * Tags the input **`tokens`** with their **pos**. It has another alias – **`tagTokens()`**.\n   *\n   * *In order to pos tag a sentence directly, use\n   * [`tagSentence`](http://winkjs.org/wink-pos-tagger/Tagger.html#tagSentence)\n   * API instead.*\n   *\n   * @method Tagger#tag\n   * @param {object[]} tokens to be pos tagged. They are array of objects and\n   * must follow the [**`wink-tokenizer`**](http://winkjs.org/wink-tokenizer/)\n   * standard.\n   * @return {object[]} pos tagged `tokens`.\n   * @example\n   * // Get `tokenizer` method from the instance of `wink-tokenizer`.\n   * var tokenize = require( 'wink-tokenizer' )().tokenize;\n   * // Tag the tokenized sentence.\n   * myTagger.tag( tokenize( 'I ate the entire pizza as I was feeling hungry.' ) );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'ate', tag: 'word', normal: 'ate', pos: 'VBD', lemma: 'eat' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'entire', tag: 'word', normal: 'entire', pos: 'JJ', lemma: 'entire' },\n   * //      { value: 'pizza', tag: 'word', normal: 'pizza', pos: 'NN', lemma: 'pizza' },\n   * //      { value: 'as', tag: 'word', normal: 'as', pos: 'IN' },\n   * //      { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'was', tag: 'word', normal: 'was', pos: 'VBD', lemma: 'be' },\n   * //      { value: 'feeling', tag: 'word', normal: 'feeling', pos: 'VBG', lemma: 'feel' },\n   * //      { value: 'hungry', tag: 'word', normal: 'hungry', pos: 'JJ', lemma: 'hungry' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n  var tag = function (tokens) {\n    // Array of \"array each possible pos\" for each token.\n    var poses = [];\n    // Temp token & word.\n    var t;\n    for (let i = 0, imax = tokens.length; i < imax; i += 1) {\n      t = tokens[i];\n      // Normalize, if configuration demands it!\n      t.normal = normalize(t.value);\n      poses.push(unigramPOSTagger(t, winkLexicon));\n    }\n    applyContextRules(tokens, poses);\n    // Lemmatize, if configuration demands...\n    lemmatize(tokens);\n    return tokens;\n  }; // tagTokens();\n\n  // ### tagRawTokens\n  /**\n   *\n   * Tags the **`raw tokens`** with their **pos**. Note, it only categorizes each\n   * token in to one of the following 3-categories (a) word, or (b) punctuation,\n   * or (c) number.\n   *\n   * *In order to pos tag a sentence directly, use\n   * [`tagSentence`](http://winkjs.org/wink-pos-tagger/Tagger.html#tagSentence)\n   * API instead.*\n   *\n   * @method Tagger#tagRawTokens\n   * @param {string[]} rawTokens to be pos tagged. They are simple array of string.\n   * @return {object[]} pos tagged `tokens`.\n   * @example\n   * var rawTokens = [ 'I', 'ate', 'the', 'entire', 'pizza', 'as', 'I', 'was', 'feeling', 'hungry', '.' ];\n   * // Tag the raw tokens.\n   * myTagger.tagRawTokens( rawTokens );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'ate', tag: 'word', normal: 'ate', pos: 'VBD', lemma: 'eat' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'entire', tag: 'word', normal: 'entire', pos: 'JJ', lemma: 'entire' },\n   * //      { value: 'pizza', tag: 'word', normal: 'pizza', pos: 'NN', lemma: 'pizza' },\n   * //      { value: 'as', tag: 'word', normal: 'as', pos: 'IN' },\n   * //      { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'was', tag: 'word', normal: 'was', pos: 'VBD', lemma: 'be' },\n   * //      { value: 'feeling', tag: 'word', normal: 'feeling', pos: 'VBG', lemma: 'feel' },\n   * //      { value: 'hungry', tag: 'word', normal: 'hungry', pos: 'JJ', lemma: 'hungry' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n  var tagRawTokens = function (rawTokens) {\n    // Will contain tokens transformed into wink format tokens\n    var wt = [];\n    var t;\n    for (var i = 0, imax = rawTokens.length; i < imax; i += 1) {\n      t = rawTokens[i];\n      if (rgxNumber.test(t)) {\n        wt.push({\n          value: t,\n          tag: 'number'\n        });\n      } else if (rgxPunctuation.test(t)) {\n        wt.push({\n          value: t,\n          tag: 'punctuation'\n        });\n      } else wt.push({\n        value: t,\n        tag: 'word'\n      });\n    }\n    return tag(wt);\n  }; // tagRawTokens()\n\n  // ### tagSentence\n  /**\n   *\n   * Tags the input `sentence` with their **pos**.\n   *\n   * @method Tagger#tagSentence\n   * @param {string} sentence to be pos tagged.\n   * @return {object[]} pos tagged `tokens.`\n   * @throws {Error} if `sentence` is not a valid string.\n   * @example\n   * myTagger.tagSentence( 'A bear just crossed the road.' );\n   * // -> [ { value: 'A', tag: 'word', normal: 'a', pos: 'DT' },\n   * //      { value: 'bear', tag: 'word', normal: 'bear', pos: 'NN', lemma: 'bear' },\n   * //      { value: 'just', tag: 'word', normal: 'just', pos: 'RB' },\n   * //      { value: 'crossed', tag: 'word', normal: 'crossed', pos: 'VBD', lemma: 'cross' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'road', tag: 'word', normal: 'road', pos: 'NN', lemma: 'road' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n   * //\n   * //\n   * myTagger.tagSentence( 'I will bear all the expenses.' );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'will', tag: 'word', normal: 'will', pos: 'MD', lemma: 'will' },\n   * //      { value: 'bear', tag: 'word', normal: 'bear', pos: 'VB', lemma: 'bear' },\n   * //      { value: 'all', tag: 'word', normal: 'all', pos: 'PDT' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'expenses', tag: 'word', normal: 'expenses', pos: 'NNS', lemma: 'expense' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n  var tagSentence = function (sentence) {\n    if (typeof sentence !== 'string') {\n      throw Error('wink-pos-tagger: input sentence must be a string, instead found: ' + typeof sentence);\n    }\n    return tag(tokenize(sentence));\n  }; // tagSentence()\n\n  methods.updateLexicon = updateLexicon;\n  methods.tag = tag;\n  methods.tagTokens = tag;\n  methods.tagRawTokens = tagRawTokens;\n  methods.tagSentence = tagSentence;\n  methods.defineConfig = defineConfig;\n  return methods;\n}; // posTagger()\n\nmodule.exports = posTagger;","map":{"version":3,"names":["helpers","require","winkLexicon","unigramPOSTagger","applyContextRules","wl","lemmatizeVBX","lemmatizeVerb","lemmatizeNNX","lemmatizeNoun","lemmatizeJJX","lemmatizeAdjective","tokenize","normalize","string","lemmaExceptions","Object","create","ai","ca","sha","wo","capA","capZ","rgxNumber","rgxPunctuation","year","posTagger","methods","updateLexicon","lexicon","validate","isObject","Error","JSON","stringify","key","defineConfig","parse","lemma","normal","lemmatize","tokens","t","v0","w","tpos","i","imax","length","value","pos","tag","poses","push","tagRawTokens","rawTokens","wt","test","tagSentence","sentence","tagTokens","module","exports"],"sources":["C:/Users/cheko/Desktop/Education/Freelance/criticowl-main/criticowl_frontend/node_modules/wink-pos-tagger/src/wink-pos-tagger.js"],"sourcesContent":["//     wink-pos-tagger\n//     English Part-of-speech (POS) tagger\n//\n//     Copyright (C) 2017-19  GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-pos-tagger”.\n//\n//     Permission is hereby granted, free of charge, to any person obtaining a\n//     copy of this software and associated documentation files (the \"Software\"),\n//     to deal in the Software without restriction, including without limitation\n//     the rights to use, copy, modify, merge, publish, distribute, sublicense,\n//     and/or sell copies of the Software, and to permit persons to whom the\n//     Software is furnished to do so, subject to the following conditions:\n//\n//     The above copyright notice and this permission notice shall be included\n//     in all copies or substantial portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n//     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n//     FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n//     LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n//     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\nvar helpers = require( 'wink-helpers' );\nvar winkLexicon = require( 'wink-lexicon/src/lexicon.js' );\nvar unigramPOSTagger = require( './unigram-tagger.js' );\nvar applyContextRules = require( './rules-engine.js' );\nvar wl = require( 'wink-lemmatizer' );\nvar lemmatizeVBX = wl.lemmatizeVerb;\nvar lemmatizeNNX = wl.lemmatizeNoun;\nvar lemmatizeJJX = wl.lemmatizeAdjective;\n// Load tokenizer, instanciate and get tokenize method; use default config.\nvar tokenize = require( 'wink-tokenizer' )().tokenize;\n// Extract string normalization function from `wink-helpers`.\nvar normalize = helpers.string.normalize;\n\nvar lemmaExceptions = Object.create( null );\nlemmaExceptions.ai = 'be';\nlemmaExceptions.ca = 'can';\nlemmaExceptions.sha = 'shall';\nlemmaExceptions[ '\\'ll' ] = lemmaExceptions.wo = 'will';\nlemmaExceptions[ '\\'ve' ] = 'have';\nlemmaExceptions[ '\\'m' ] = 'am';\nlemmaExceptions[ '\\'re' ] = 'be';\nlemmaExceptions[ 'n\\'t' ] = 'not';\nlemmaExceptions[ '\\'d' ] = 'would';\n// Needed for simple NNP transformation rule.\nconst capA = 'A';\nconst capZ = 'Z';\n// Required in raw tokens tagging\nconst rgxNumber = /^\\d+\\/\\d+|\\d(?:[\\.\\,\\-\\/]?\\d)*(?:\\.\\d+)?$/;\nconst rgxPunctuation = /^[\\’\\'\\‘\\’\\`\\“\\”\\\"\\[\\]\\(\\)\\{\\}\\…\\,\\.\\!\\;\\?\\-\\:]+$/;\n// Used in tagging years.\nconst year = Object.create( null );\nyear[ '1990s' ] = 'CD';\nyear[ '1980s' ] = 'CD';\nyear[ '1970s' ] = 'CD';\nyear[ '1960s' ] = 'CD';\nyear[ '1950s' ] = 'CD';\nyear[ '1940s' ] = 'CD';\nyear[ '1930s' ] = 'CD';\nyear[ '1910s' ] = 'CD';\nyear[ 'mid-1990s' ] = 'CD';\nyear[ 'mid-1980s' ] = 'CD';\nyear[ 'mid-1970s' ] = 'CD';\nyear[ 'mid-1960s' ] = 'CD';\nyear[ 'mid-1950s' ] = 'CD';\nyear[ 'mid-1940s' ] = 'CD';\nyear[ 'mid-1930s' ] = 'CD';\nyear[ 'mid-1920s' ] = 'CD';\nyear[ 'mid-1910s' ] = 'CD';\n\n// ### posTagger\n/**\n *\n * Creates an instance of {@link Tagger}.\n *\n * @return {Tagger} object conatining set of API methods for pos-tagging.\n * @example\n * // Load wink tokenizer.\n * var tagger = require( 'wink-pos-tagger' );\n * // Create your instance of wink tokenizer.\n * var myTagger = posTagger();\n*/\nvar posTagger = function ( ) {\n\n  /**\n  * @classdesc Tagger class\n  * @class Tagger\n  * @hideconstructor\n  */\n  var methods = Object.create( null );\n\n  // ### updateLexicon\n  /**\n   *\n   * Updates the internal lexicon using the input `lexicon`. If a word/pos pair\n   * is found in the internal lexicon then it's value is updated with the new pos;\n   * otherwise it added.\n   *\n   * @method Tagger#updateLexicon\n   * @param {object} lexicon containing **`word/pos`** pairs to be added to or\n   * replaced in the existing lexicon. The `pos` should be an array containing\n   * pos tags, with the first one as the most frequently used POS. The `word` is\n   * normalized before updating the internal lexicon.\n   * @return {undefined} Nothing!\n   * @throws {Error} if `lexicon` is not a valid JS object.\n   * @example\n   * myTagger.updateLexicon( { Obama: [ 'NNP' ] } );\n  */\n  var updateLexicon = function ( lexicon ) {\n    if ( !helpers.validate.isObject( lexicon ) ) {\n      throw Error( 'wink-pos-tagger/updateLexicon: lexicon must be an object, instead found: ' + JSON.stringify( lexicon ) );\n    }\n    // Update winkLexicon but with **normalized** key.\n    for ( var key in lexicon ) winkLexicon[ normalize( key ) ] = lexicon[ key ]; // eslint-disable-line guard-for-in\n  }; // updateLexicon()\n\n  // ### defineConfig\n  /**\n   *\n   * This API has no effect. It has been maintained for compatibility purpose.\n   * The `wink-tokenizer` will now always add **lemma** and **normal** forms.\n   * Note, lemmas are added only for **nouns** (excluding proper noun), **verbs** and\n   * **adjectives**.\n   *\n   * @method Tagger#defineConfig\n   * @return {object} always as `{ lemma: true, normal: true }`.\n   * @example\n   * // There will not be any effect:\n   * var myTagger.defineConfig( { lemma: false } );\n   * // -> { lemma: true, normal: true }\n  */\n  var defineConfig = function ( ) {\n    // Return a copy of configuration object.\n    return ( JSON.parse( JSON.stringify( { lemma: true, normal: true } ) ) );\n  }; // defineConfig()\n\n  // ### lemmatize\n  /**\n   *\n   * Performs lemmatization; also applies NNP transformation rules for captitalized\n   * nouns and adjectives and CD rule for years.\n   *\n   * @method Tagger#lemmatize\n   * @param {object[]} tokens to be lemmatized.\n   * @return {object[]} lemmatized tokens.\n   * @private\n  */\n  var lemmatize = function ( tokens ) {\n    var t, v0, w;\n    var lemma;\n    var tpos;\n    for ( let i = 0, imax = tokens.length; i < imax; i += 1 ) {\n      t = tokens[ i ];\n      w = t.normal;\n      v0 = t.value[ 0 ];\n      tpos = year[ w ];\n      if ( tpos ) t.pos = 'CD';\n      // First handle exceptions arising out of contractions.\n      lemma = lemmaExceptions[ w ];\n      if ( lemma ) {\n        t.lemma = lemma;\n      } else {\n        // Otherwise use lemmatizer.\n        switch ( t.pos[ 0 ] ) {\n          case 'J':\n            if ( ( v0 >= capA ) && ( v0 <= capZ ) ) {\n              t.lemma = w;\n              t.pos = 'NNP';\n            } else {\n              t.lemma = ( t.pos.length > 2 ) ? lemmatizeJJX( w ) : w;\n            }\n            break;\n          case 'V':\n            t.lemma = ( t.pos.length > 2 ) ?\n                        ( ( t.normal === '\\'s') ? 'be' : lemmatizeVBX( w ) ) :\n                        w;\n            break;\n          case 'N':\n            if ( ( v0 >= capA ) && ( v0 <= capZ ) ) {\n              t.lemma = w;\n              t.pos = 'NNP';\n            } else {\n              // No lemmatization of NNPs please!\n              t.lemma = ( t.pos !== 'NNP' && t.pos.length > 2 ) ? lemmatizeNNX( w ) : w;\n            }\n            break;\n          case 'M':\n            t.lemma = lemmatizeVBX( w );\n            break;\n          default:\n            // Do nothing!\n        } // swtich\n      } // if\n    }\n\n    return tokens;\n  }; // lemmatize()\n\n  // ### tag\n  /**\n   *\n   * Tags the input **`tokens`** with their **pos**. It has another alias – **`tagTokens()`**.\n   *\n   * *In order to pos tag a sentence directly, use\n   * [`tagSentence`](http://winkjs.org/wink-pos-tagger/Tagger.html#tagSentence)\n   * API instead.*\n   *\n   * @method Tagger#tag\n   * @param {object[]} tokens to be pos tagged. They are array of objects and\n   * must follow the [**`wink-tokenizer`**](http://winkjs.org/wink-tokenizer/)\n   * standard.\n   * @return {object[]} pos tagged `tokens`.\n   * @example\n   * // Get `tokenizer` method from the instance of `wink-tokenizer`.\n   * var tokenize = require( 'wink-tokenizer' )().tokenize;\n   * // Tag the tokenized sentence.\n   * myTagger.tag( tokenize( 'I ate the entire pizza as I was feeling hungry.' ) );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'ate', tag: 'word', normal: 'ate', pos: 'VBD', lemma: 'eat' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'entire', tag: 'word', normal: 'entire', pos: 'JJ', lemma: 'entire' },\n   * //      { value: 'pizza', tag: 'word', normal: 'pizza', pos: 'NN', lemma: 'pizza' },\n   * //      { value: 'as', tag: 'word', normal: 'as', pos: 'IN' },\n   * //      { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'was', tag: 'word', normal: 'was', pos: 'VBD', lemma: 'be' },\n   * //      { value: 'feeling', tag: 'word', normal: 'feeling', pos: 'VBG', lemma: 'feel' },\n   * //      { value: 'hungry', tag: 'word', normal: 'hungry', pos: 'JJ', lemma: 'hungry' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n  var tag = function ( tokens ) {\n    // Array of \"array each possible pos\" for each token.\n    var poses = [];\n    // Temp token & word.\n    var t;\n    for ( let i = 0, imax = tokens.length; i < imax; i += 1 ) {\n      t = tokens[ i ];\n      // Normalize, if configuration demands it!\n      t.normal = normalize( t.value );\n      poses.push( unigramPOSTagger( t, winkLexicon ) );\n    }\n    applyContextRules( tokens, poses );\n    // Lemmatize, if configuration demands...\n    lemmatize( tokens );\n    return tokens;\n  }; // tagTokens();\n\n  // ### tagRawTokens\n  /**\n   *\n   * Tags the **`raw tokens`** with their **pos**. Note, it only categorizes each\n   * token in to one of the following 3-categories (a) word, or (b) punctuation,\n   * or (c) number.\n   *\n   * *In order to pos tag a sentence directly, use\n   * [`tagSentence`](http://winkjs.org/wink-pos-tagger/Tagger.html#tagSentence)\n   * API instead.*\n   *\n   * @method Tagger#tagRawTokens\n   * @param {string[]} rawTokens to be pos tagged. They are simple array of string.\n   * @return {object[]} pos tagged `tokens`.\n   * @example\n   * var rawTokens = [ 'I', 'ate', 'the', 'entire', 'pizza', 'as', 'I', 'was', 'feeling', 'hungry', '.' ];\n   * // Tag the raw tokens.\n   * myTagger.tagRawTokens( rawTokens );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'ate', tag: 'word', normal: 'ate', pos: 'VBD', lemma: 'eat' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'entire', tag: 'word', normal: 'entire', pos: 'JJ', lemma: 'entire' },\n   * //      { value: 'pizza', tag: 'word', normal: 'pizza', pos: 'NN', lemma: 'pizza' },\n   * //      { value: 'as', tag: 'word', normal: 'as', pos: 'IN' },\n   * //      { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'was', tag: 'word', normal: 'was', pos: 'VBD', lemma: 'be' },\n   * //      { value: 'feeling', tag: 'word', normal: 'feeling', pos: 'VBG', lemma: 'feel' },\n   * //      { value: 'hungry', tag: 'word', normal: 'hungry', pos: 'JJ', lemma: 'hungry' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n  var tagRawTokens = function ( rawTokens ) {\n    // Will contain tokens transformed into wink format tokens\n    var wt = [];\n    var t;\n    for ( var i = 0, imax = rawTokens.length; i < imax; i += 1 ) {\n      t = rawTokens[ i ];\n      if ( rgxNumber.test( t ) ) {\n        wt.push( { value: t, tag: 'number' } );\n      } else if ( rgxPunctuation.test( t ) ) {\n        wt.push( { value: t, tag: 'punctuation' } );\n      } else wt.push( { value: t, tag: 'word' } );\n    }\n\n    return tag( wt );\n  }; // tagRawTokens()\n\n  // ### tagSentence\n  /**\n   *\n   * Tags the input `sentence` with their **pos**.\n   *\n   * @method Tagger#tagSentence\n   * @param {string} sentence to be pos tagged.\n   * @return {object[]} pos tagged `tokens.`\n   * @throws {Error} if `sentence` is not a valid string.\n   * @example\n   * myTagger.tagSentence( 'A bear just crossed the road.' );\n   * // -> [ { value: 'A', tag: 'word', normal: 'a', pos: 'DT' },\n   * //      { value: 'bear', tag: 'word', normal: 'bear', pos: 'NN', lemma: 'bear' },\n   * //      { value: 'just', tag: 'word', normal: 'just', pos: 'RB' },\n   * //      { value: 'crossed', tag: 'word', normal: 'crossed', pos: 'VBD', lemma: 'cross' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'road', tag: 'word', normal: 'road', pos: 'NN', lemma: 'road' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n   * //\n   * //\n   * myTagger.tagSentence( 'I will bear all the expenses.' );\n   * // -> [ { value: 'I', tag: 'word', normal: 'i', pos: 'PRP' },\n   * //      { value: 'will', tag: 'word', normal: 'will', pos: 'MD', lemma: 'will' },\n   * //      { value: 'bear', tag: 'word', normal: 'bear', pos: 'VB', lemma: 'bear' },\n   * //      { value: 'all', tag: 'word', normal: 'all', pos: 'PDT' },\n   * //      { value: 'the', tag: 'word', normal: 'the', pos: 'DT' },\n   * //      { value: 'expenses', tag: 'word', normal: 'expenses', pos: 'NNS', lemma: 'expense' },\n   * //      { value: '.', tag: 'punctuation', normal: '.', pos: '.' } ]\n  */\n  var tagSentence = function ( sentence ) {\n    if ( typeof sentence !== 'string' ) {\n      throw Error( 'wink-pos-tagger: input sentence must be a string, instead found: ' + typeof sentence );\n    }\n    return tag( tokenize( sentence ) );\n  }; // tagSentence()\n\n  methods.updateLexicon = updateLexicon;\n  methods.tag = tag;\n  methods.tagTokens = tag;\n  methods.tagRawTokens = tagRawTokens;\n  methods.tagSentence = tagSentence;\n  methods.defineConfig = defineConfig;\n\n  return methods;\n}; // posTagger()\n\nmodule.exports = posTagger;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,IAAIA,OAAO,GAAGC,OAAO,CAAE,cAAe,CAAC;AACvC,IAAIC,WAAW,GAAGD,OAAO,CAAE,6BAA8B,CAAC;AAC1D,IAAIE,gBAAgB,GAAGF,OAAO,CAAE,qBAAsB,CAAC;AACvD,IAAIG,iBAAiB,GAAGH,OAAO,CAAE,mBAAoB,CAAC;AACtD,IAAII,EAAE,GAAGJ,OAAO,CAAE,iBAAkB,CAAC;AACrC,IAAIK,YAAY,GAAGD,EAAE,CAACE,aAAa;AACnC,IAAIC,YAAY,GAAGH,EAAE,CAACI,aAAa;AACnC,IAAIC,YAAY,GAAGL,EAAE,CAACM,kBAAkB;AACxC;AACA,IAAIC,QAAQ,GAAGX,OAAO,CAAE,gBAAiB,CAAC,CAAC,CAAC,CAACW,QAAQ;AACrD;AACA,IAAIC,SAAS,GAAGb,OAAO,CAACc,MAAM,CAACD,SAAS;AAExC,IAAIE,eAAe,GAAGC,MAAM,CAACC,MAAM,CAAE,IAAK,CAAC;AAC3CF,eAAe,CAACG,EAAE,GAAG,IAAI;AACzBH,eAAe,CAACI,EAAE,GAAG,KAAK;AAC1BJ,eAAe,CAACK,GAAG,GAAG,OAAO;AAC7BL,eAAe,CAAE,MAAM,CAAE,GAAGA,eAAe,CAACM,EAAE,GAAG,MAAM;AACvDN,eAAe,CAAE,MAAM,CAAE,GAAG,MAAM;AAClCA,eAAe,CAAE,KAAK,CAAE,GAAG,IAAI;AAC/BA,eAAe,CAAE,MAAM,CAAE,GAAG,IAAI;AAChCA,eAAe,CAAE,MAAM,CAAE,GAAG,KAAK;AACjCA,eAAe,CAAE,KAAK,CAAE,GAAG,OAAO;AAClC;AACA,MAAMO,IAAI,GAAG,GAAG;AAChB,MAAMC,IAAI,GAAG,GAAG;AAChB;AACA,MAAMC,SAAS,GAAG,2CAA2C;AAC7D,MAAMC,cAAc,GAAG,mDAAmD;AAC1E;AACA,MAAMC,IAAI,GAAGV,MAAM,CAACC,MAAM,CAAE,IAAK,CAAC;AAClCS,IAAI,CAAE,OAAO,CAAE,GAAG,IAAI;AACtBA,IAAI,CAAE,OAAO,CAAE,GAAG,IAAI;AACtBA,IAAI,CAAE,OAAO,CAAE,GAAG,IAAI;AACtBA,IAAI,CAAE,OAAO,CAAE,GAAG,IAAI;AACtBA,IAAI,CAAE,OAAO,CAAE,GAAG,IAAI;AACtBA,IAAI,CAAE,OAAO,CAAE,GAAG,IAAI;AACtBA,IAAI,CAAE,OAAO,CAAE,GAAG,IAAI;AACtBA,IAAI,CAAE,OAAO,CAAE,GAAG,IAAI;AACtBA,IAAI,CAAE,WAAW,CAAE,GAAG,IAAI;AAC1BA,IAAI,CAAE,WAAW,CAAE,GAAG,IAAI;AAC1BA,IAAI,CAAE,WAAW,CAAE,GAAG,IAAI;AAC1BA,IAAI,CAAE,WAAW,CAAE,GAAG,IAAI;AAC1BA,IAAI,CAAE,WAAW,CAAE,GAAG,IAAI;AAC1BA,IAAI,CAAE,WAAW,CAAE,GAAG,IAAI;AAC1BA,IAAI,CAAE,WAAW,CAAE,GAAG,IAAI;AAC1BA,IAAI,CAAE,WAAW,CAAE,GAAG,IAAI;AAC1BA,IAAI,CAAE,WAAW,CAAE,GAAG,IAAI;;AAE1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIC,SAAS,GAAG,SAAAA,CAAA,EAAa;EAE3B;AACF;AACA;AACA;AACA;EACE,IAAIC,OAAO,GAAGZ,MAAM,CAACC,MAAM,CAAE,IAAK,CAAC;;EAEnC;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIY,aAAa,GAAG,SAAAA,CAAWC,OAAO,EAAG;IACvC,IAAK,CAAC9B,OAAO,CAAC+B,QAAQ,CAACC,QAAQ,CAAEF,OAAQ,CAAC,EAAG;MAC3C,MAAMG,KAAK,CAAE,2EAA2E,GAAGC,IAAI,CAACC,SAAS,CAAEL,OAAQ,CAAE,CAAC;IACxH;IACA;IACA,KAAM,IAAIM,GAAG,IAAIN,OAAO,EAAG5B,WAAW,CAAEW,SAAS,CAAEuB,GAAI,CAAC,CAAE,GAAGN,OAAO,CAAEM,GAAG,CAAE,CAAC,CAAC;EAC/E,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIC,YAAY,GAAG,SAAAA,CAAA,EAAa;IAC9B;IACA,OAASH,IAAI,CAACI,KAAK,CAAEJ,IAAI,CAACC,SAAS,CAAE;MAAEI,KAAK,EAAE,IAAI;MAAEC,MAAM,EAAE;IAAK,CAAE,CAAE,CAAC;EACxE,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIC,SAAS,GAAG,SAAAA,CAAWC,MAAM,EAAG;IAClC,IAAIC,CAAC,EAAEC,EAAE,EAAEC,CAAC;IACZ,IAAIN,KAAK;IACT,IAAIO,IAAI;IACR,KAAM,IAAIC,CAAC,GAAG,CAAC,EAAEC,IAAI,GAAGN,MAAM,CAACO,MAAM,EAAEF,CAAC,GAAGC,IAAI,EAAED,CAAC,IAAI,CAAC,EAAG;MACxDJ,CAAC,GAAGD,MAAM,CAAEK,CAAC,CAAE;MACfF,CAAC,GAAGF,CAAC,CAACH,MAAM;MACZI,EAAE,GAAGD,CAAC,CAACO,KAAK,CAAE,CAAC,CAAE;MACjBJ,IAAI,GAAGpB,IAAI,CAAEmB,CAAC,CAAE;MAChB,IAAKC,IAAI,EAAGH,CAAC,CAACQ,GAAG,GAAG,IAAI;MACxB;MACAZ,KAAK,GAAGxB,eAAe,CAAE8B,CAAC,CAAE;MAC5B,IAAKN,KAAK,EAAG;QACXI,CAAC,CAACJ,KAAK,GAAGA,KAAK;MACjB,CAAC,MAAM;QACL;QACA,QAASI,CAAC,CAACQ,GAAG,CAAE,CAAC,CAAE;UACjB,KAAK,GAAG;YACN,IAAOP,EAAE,IAAItB,IAAI,IAAQsB,EAAE,IAAIrB,IAAM,EAAG;cACtCoB,CAAC,CAACJ,KAAK,GAAGM,CAAC;cACXF,CAAC,CAACQ,GAAG,GAAG,KAAK;YACf,CAAC,MAAM;cACLR,CAAC,CAACJ,KAAK,GAAKI,CAAC,CAACQ,GAAG,CAACF,MAAM,GAAG,CAAC,GAAKvC,YAAY,CAAEmC,CAAE,CAAC,GAAGA,CAAC;YACxD;YACA;UACF,KAAK,GAAG;YACNF,CAAC,CAACJ,KAAK,GAAKI,CAAC,CAACQ,GAAG,CAACF,MAAM,GAAG,CAAC,GACZN,CAAC,CAACH,MAAM,KAAK,KAAK,GAAI,IAAI,GAAGlC,YAAY,CAAEuC,CAAE,CAAC,GAClDA,CAAC;YACb;UACF,KAAK,GAAG;YACN,IAAOD,EAAE,IAAItB,IAAI,IAAQsB,EAAE,IAAIrB,IAAM,EAAG;cACtCoB,CAAC,CAACJ,KAAK,GAAGM,CAAC;cACXF,CAAC,CAACQ,GAAG,GAAG,KAAK;YACf,CAAC,MAAM;cACL;cACAR,CAAC,CAACJ,KAAK,GAAKI,CAAC,CAACQ,GAAG,KAAK,KAAK,IAAIR,CAAC,CAACQ,GAAG,CAACF,MAAM,GAAG,CAAC,GAAKzC,YAAY,CAAEqC,CAAE,CAAC,GAAGA,CAAC;YAC3E;YACA;UACF,KAAK,GAAG;YACNF,CAAC,CAACJ,KAAK,GAAGjC,YAAY,CAAEuC,CAAE,CAAC;YAC3B;UACF;UACE;QACJ,CAAC,CAAC;MACJ,CAAC,CAAC;IACJ;IAEA,OAAOH,MAAM;EACf,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIU,GAAG,GAAG,SAAAA,CAAWV,MAAM,EAAG;IAC5B;IACA,IAAIW,KAAK,GAAG,EAAE;IACd;IACA,IAAIV,CAAC;IACL,KAAM,IAAII,CAAC,GAAG,CAAC,EAAEC,IAAI,GAAGN,MAAM,CAACO,MAAM,EAAEF,CAAC,GAAGC,IAAI,EAAED,CAAC,IAAI,CAAC,EAAG;MACxDJ,CAAC,GAAGD,MAAM,CAAEK,CAAC,CAAE;MACf;MACAJ,CAAC,CAACH,MAAM,GAAG3B,SAAS,CAAE8B,CAAC,CAACO,KAAM,CAAC;MAC/BG,KAAK,CAACC,IAAI,CAAEnD,gBAAgB,CAAEwC,CAAC,EAAEzC,WAAY,CAAE,CAAC;IAClD;IACAE,iBAAiB,CAAEsC,MAAM,EAAEW,KAAM,CAAC;IAClC;IACAZ,SAAS,CAAEC,MAAO,CAAC;IACnB,OAAOA,MAAM;EACf,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIa,YAAY,GAAG,SAAAA,CAAWC,SAAS,EAAG;IACxC;IACA,IAAIC,EAAE,GAAG,EAAE;IACX,IAAId,CAAC;IACL,KAAM,IAAII,CAAC,GAAG,CAAC,EAAEC,IAAI,GAAGQ,SAAS,CAACP,MAAM,EAAEF,CAAC,GAAGC,IAAI,EAAED,CAAC,IAAI,CAAC,EAAG;MAC3DJ,CAAC,GAAGa,SAAS,CAAET,CAAC,CAAE;MAClB,IAAKvB,SAAS,CAACkC,IAAI,CAAEf,CAAE,CAAC,EAAG;QACzBc,EAAE,CAACH,IAAI,CAAE;UAAEJ,KAAK,EAAEP,CAAC;UAAES,GAAG,EAAE;QAAS,CAAE,CAAC;MACxC,CAAC,MAAM,IAAK3B,cAAc,CAACiC,IAAI,CAAEf,CAAE,CAAC,EAAG;QACrCc,EAAE,CAACH,IAAI,CAAE;UAAEJ,KAAK,EAAEP,CAAC;UAAES,GAAG,EAAE;QAAc,CAAE,CAAC;MAC7C,CAAC,MAAMK,EAAE,CAACH,IAAI,CAAE;QAAEJ,KAAK,EAAEP,CAAC;QAAES,GAAG,EAAE;MAAO,CAAE,CAAC;IAC7C;IAEA,OAAOA,GAAG,CAAEK,EAAG,CAAC;EAClB,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIE,WAAW,GAAG,SAAAA,CAAWC,QAAQ,EAAG;IACtC,IAAK,OAAOA,QAAQ,KAAK,QAAQ,EAAG;MAClC,MAAM3B,KAAK,CAAE,mEAAmE,GAAG,OAAO2B,QAAS,CAAC;IACtG;IACA,OAAOR,GAAG,CAAExC,QAAQ,CAAEgD,QAAS,CAAE,CAAC;EACpC,CAAC,CAAC,CAAC;;EAEHhC,OAAO,CAACC,aAAa,GAAGA,aAAa;EACrCD,OAAO,CAACwB,GAAG,GAAGA,GAAG;EACjBxB,OAAO,CAACiC,SAAS,GAAGT,GAAG;EACvBxB,OAAO,CAAC2B,YAAY,GAAGA,YAAY;EACnC3B,OAAO,CAAC+B,WAAW,GAAGA,WAAW;EACjC/B,OAAO,CAACS,YAAY,GAAGA,YAAY;EAEnC,OAAOT,OAAO;AAChB,CAAC,CAAC,CAAC;;AAEHkC,MAAM,CAACC,OAAO,GAAGpC,SAAS","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}