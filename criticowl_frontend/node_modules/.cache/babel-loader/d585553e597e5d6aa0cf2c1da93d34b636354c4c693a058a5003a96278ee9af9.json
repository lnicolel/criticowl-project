{"ast":null,"code":"//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-nlp”.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-underscore-dangle */\n\n// Used in accessing the regex and its category from `rgxs`.\nconst RGX = 0;\nconst CAT = 1;\n// SPECIAL REGULAR EXPRESSIONS:\n// Regex to handle short forms or abbreviations.\nvar rgxShortFormDot = /^(?:(?:[A-Z])(?:\\.))+$/i;\nvar rgxShortForm = /^(?:(?:[A-Z])(?:\\.))+[a-z]?$/i;\n// Regex process hyphenated words.\nvar rgxHyphens = /[\\-\\–\\—]/gi;\nvar rgxPeriod = /[\\.]/gi;\nvar rgxNumber = /[0-9]/;\n\n// ### tokenizer\n/**\n *\n * Creates an instance of `tokenizer`.\n *\n * @param {object} categories token categories, as obtained via the language model.\n * @param {object} preserve rules for hyphenation preservation.\n * @return {function} for recursive tokenization.\n * @private\n*/\nvar tokenizer = function (categories, preserve) {\n  // Function to add tokens to the `doc()`.\n  var addToken;\n  var addTokenIfInCache;\n  // Function to test if lexeme exists via `doc()`.\n  var isLexeme;\n  // Preceding Spaces — special need for recursive tokenizer.\n  var ps = 0;\n  // Will only be needed for the first token, after that it si all zero (ps)!\n  var nonBreakingSpaces = null;\n\n  // ### pushHyphenatedToken\n  /**\n   *\n   * Pushes the incoming `tkn` after handling hyphens, if any:\n   * 1. Use it as-is if it is a valid lexeme or contains a number.\n   * 2. Use it as-is if does not contain hyphens.\n   * 3. Otherwise apply rules.\n   *\n   * @param {string} tkn to be processed as per rules hyphenation rules in `preserve`.\n   * @param {array} tokens into which the (split) `tkn` is pushed.\n   * @returns {void} nothing!\n   * @private\n  */\n  var pushHyphenatedToken = function (tkn, tokens) {\n    // Will contain pure alpha words, obtained by splitting on `rgxHyphens`.\n    var words;\n    // Will contain mathed hyphens.\n    var hyphens;\n    // Helper variables.\n    var i, k, last;\n\n    // If a token is a valid lexeme or contains one or more number, dont touch it.\n    if (isLexeme(tkn) || rgxNumber.test(tkn)) {\n      tokens.push([tkn, categories.word]);\n      return;\n    }\n    hyphens = tkn.match(rgxHyphens);\n    // If there are no hyphens in the word, dont touch it.\n    if (hyphens === null) {\n      tokens.push([tkn, categories.word]);\n      return;\n    }\n\n    // Word is hyphenated, process it according to the rules specified in `preserve`.\n    words = tkn.split(rgxHyphens);\n    last = words.length - 1;\n    if (preserve.prefix[words[0]] || preserve.suffix[words[last]]) {\n      tokens.push([tkn, categories.word]);\n      return;\n    }\n    k = 0;\n    for (i = 0; i < words.length; i += 1) {\n      // Do not push any empty token!\n      if (words[i] !== '') {\n        tokens.push([words[i], categories.word]);\n      }\n      if (k < hyphens.length) {\n        tokens.push([hyphens[k], categories.punctuation]);\n      }\n      k += 1;\n    }\n  }; // pushHyphenatedToken()\n\n  // ### pushWordToken\n  /**\n   *\n   * Pushes the incoming `tkn` after handling periods and hyphens present:\n   * 1. Use it as-is if it is a valid lexeme or a short form ending with a period.\n   * 2. Split on period and the successively assemble tokens using matches & splits.\n   * 3. Finally send each such assembled token down for handling hyphenated word.\n   *\n   * @param {string} tkn to be processed and pushed.\n   * @param {array} tokens into which the (split) `tkn` is pushed.\n   * @returns {void} nothing!\n   * @private\n  */\n  var pushWordToken = function (tkn, tokens) {\n    // Will contain words, obtained by splitting on `rgxPeriod`.\n    var words;\n    // Will contain matched periods.\n    var periods;\n    // Helper variables:<br/>\n    // Index variables\n    var i, k;\n    // Used in successively assembling a potential token from matches & words\n    // (i.e. splits), if word has periods.\n    var currBuild = '';\n    var nextBuild = '';\n\n    // If a token is a **valid lexeme**, or it is **short form ending with a\n    // period** (e.g. dot) then _dont touch it._\n    if (isLexeme(tkn) || rgxShortFormDot.test(tkn)) {\n      tokens.push([tkn, categories.word]);\n      return;\n    }\n\n    // Start by matching with periods\n    periods = tkn.match(rgxPeriod);\n    // If there are no periods in the word, dont touch it.\n    if (periods === null) {\n      pushHyphenatedToken(tkn, tokens);\n      return;\n    }\n\n    // Word has periods, therefore process it:\n    words = tkn.split(rgxPeriod);\n    k = 0;\n    for (i = 0; i < words.length; i += 1) {\n      // Build next potential token by joining the current build with the next word.\n      nextBuild = currBuild + words[i];\n      // If it is a valid possibility, then continue building it.\n      if (rgxShortForm.test(nextBuild) || isLexeme(nextBuild) && nextBuild.length > 2 || currBuild === '') {\n        currBuild = nextBuild;\n      } else {\n        // Else send it down to handle hyphenated word.\n        pushHyphenatedToken(currBuild, tokens);\n        // Reset builds.\n        currBuild = words[i];\n        nextBuild = '';\n      }\n      if (k < periods.length) {\n        // In the same manner handle period sign.\n        nextBuild = currBuild + periods[k];\n        if (rgxShortForm.test(nextBuild) || isLexeme(nextBuild) && nextBuild.length > 2) {\n          currBuild = nextBuild;\n        } else {\n          pushHyphenatedToken(currBuild, tokens);\n          tokens.push([periods[k], categories.punctuation]);\n          currBuild = '';\n          nextBuild = '';\n        }\n      }\n      k += 1;\n    }\n    // Handle the last piece if applicable.\n    if (currBuild !== '') pushHyphenatedToken(currBuild, tokens);\n  }; // pushWordToken()\n\n  // ### tokenizeTextUnit\n  /**\n   *\n   * Attempts to tokenize the input `text` using the `rgxSplit`. The tokenization\n   * is carried out by combining the regex matches and splits in the right sequence.\n   * The matches are the *real tokens*, whereas splits are text units that are\n   * tokenized in later rounds! The real tokens (i.e. matches) are pushed as\n   * `object` and splits as `string`.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} rgxSplit object containing the regex and it's category.\n   * @return {array} of tokens.\n   * @private\n  */\n  var tokenizeTextUnit = function (text, rgxSplit) {\n    // Regex matches go here; note each match is a token and has the same tag\n    // as of regex's category.\n    var matches = text.match(rgxSplit[RGX]);\n    // Balance is \"what needs to be tokenized\".\n    var balance = text.split(rgxSplit[RGX]);\n    // The result, in form of combination of tokens & matches, is captured here.\n    var tokens = [];\n    // The tag;\n    var tag = rgxSplit[CAT];\n    // Helper variables.\n    var i, imax, k, t; // Temp token.\n    // tp; // Temp token with a period sign in end.\n\n    // console.log( matches, balance, text, tag, balance[ 1 ] ); // eslint-disable-line no-console\n    // A `null` value means it is equivalent to no matches i.e. an empty array.\n    matches = matches ? matches : [];\n    // Handle cases where the word is ending with period for **word category**.\n    // Iterate in [ m0 b1 m1 ... ] pattern as `b0` has no value here.\n    // *** COMMENTED out after `pushWordToken()`:\n    // k = 0;\n    // if ( tag === categories.word ) {\n    //   for ( i = 1, imax = balance.length; i < imax; i += 1 ) {\n    //     t = balance[ i ];\n    //     if ( k < matches.length && t[ 0 ] === '.' ) {\n    //       tp = matches[ k ] + '.';\n    //       if ( isLexeme( tp ) || rgxShortForm.test( tp ) ) {\n    //         matches[ k ] = tp;\n    //         balance[ i ] = t.slice( 1 );\n    //       }\n    //     }\n    //     k += 1;\n    //   }\n    // }\n\n    // console.log( matches, balance, text, tag, balance[ 1 ] ); // eslint-disable-line no-console\n    // Combine tokens & matches in the following pattern [ b0 m0 b1 m1 ... ]\n    k = 0;\n    for (i = 0, imax = balance.length; i < imax; i += 1) {\n      t = balance[i];\n      t = t.trim();\n      if (t) tokens.push(t);\n      if (k < matches.length) {\n        if (tag === categories.word) {\n          // Handle special cases for words via:\n          pushWordToken(matches[k], tokens);\n        } else {\n          tokens.push([matches[k], tag]);\n        }\n      }\n      k += 1;\n    }\n    return tokens;\n  }; // tokenizeTextUnit()\n\n  // ### tokenizeTextRecursively\n  /**\n   *\n   * Tokenizes the input text recursively using the array of `regexes` and then\n   * the `tokenizeTextUnit()` function. If (or whenever) the `regexes` becomes\n   * empty, it simply splits the text on non-word characters instead of using\n   * the `tokenizeTextUnit()` function.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} regexes object containing the regex and it's category.\n   * @return {undefined} nothing!\n   * @private\n  */\n  var tokenizeTextRecursively = function (text, regexes) {\n    var sentence = text.trim();\n    var tokens = [];\n    // Helpers – for loop variables & token category.\n    var i, imax;\n    var cat;\n    if (!regexes.length) {\n      // No regex left, this is the true **unk**.\n      // Becuase it is `UNK`, we can use `addToken` instead of attempting\n      // `addTokenIfInCache`.\n      addToken(text, categories.unk, ps, nonBreakingSpaces);\n      ps = 0;\n      return;\n    }\n    var rgx = regexes[0];\n    tokens = tokenizeTextUnit(sentence, rgx);\n    for (i = 0, imax = tokens.length; i < imax; i += 1) {\n      if (typeof tokens[i] === 'string') {\n        // Strings become candidates for further tokenization.\n        tokenizeTextRecursively(tokens[i], regexes.slice(1));\n      } else {\n        // Use the passed value of preceding spaces only once!\n        // First try cache, otherwise make a direct addition. This ensures\n        // processing of expansions.\n        cat = addTokenIfInCache(tokens[i][0], ps, nonBreakingSpaces);\n        if (cat === categories.unk) addToken(tokens[i][0], tokens[i][1], ps, nonBreakingSpaces);\n        // Reset `ps` to **0** as there can never be spaces in a text passed to\n        // this tokenizer.\n        ps = 0;\n      }\n    }\n  }; // tokenizeTextRecursively()\n\n  // ### tokenize\n  /**\n   *\n   * Tokenizes the input `sentence` using the function `tokenizeTextRecursively()`.\n   * This acts as the fall back tokenizer to the **linear tokenizer**.\n   *\n   * @method Tokenizer#tokenize\n   * @param {RegExp} rgxs containg regexes for parsing.\n   * @param {string} text the input sentence.\n   * @param {number} precedingSpaces to the text\n   * @param {object} doc contains the document; used here for adding tokens.\n   * @param {array}  nbsp contains non breaking spaces details.\n   * @return {void} nothing!\n   * `value` and its `tag` identifying the type of the token.\n   * @private\n  */\n  var tokenize = function (rgxs, text, precedingSpaces, doc, nbsp) {\n    // Cache frequently used doc methods.\n    addToken = doc._addToken;\n    addTokenIfInCache = doc._addTokenIfInCache;\n    isLexeme = doc.isLexeme;\n    // Set `ps` to the passed value of preceding spaces, it will be reset to **0**\n    // after first use during recursion.\n    ps = precedingSpaces;\n    nonBreakingSpaces = nbsp;\n    tokenizeTextRecursively(text, rgxs, precedingSpaces);\n  }; // tokenize()\n\n  return tokenize;\n};\nmodule.exports = tokenizer;","map":{"version":3,"names":["RGX","CAT","rgxShortFormDot","rgxShortForm","rgxHyphens","rgxPeriod","rgxNumber","tokenizer","categories","preserve","addToken","addTokenIfInCache","isLexeme","ps","nonBreakingSpaces","pushHyphenatedToken","tkn","tokens","words","hyphens","i","k","last","test","push","word","match","split","length","prefix","suffix","punctuation","pushWordToken","periods","currBuild","nextBuild","tokenizeTextUnit","text","rgxSplit","matches","balance","tag","imax","t","trim","tokenizeTextRecursively","regexes","sentence","cat","unk","rgx","slice","tokenize","rgxs","precedingSpaces","doc","nbsp","_addToken","_addTokenIfInCache","module","exports"],"sources":["C:/Users/cheko/Desktop/Education/Freelance/criticowl-main/criticowl_frontend/node_modules/wink-nlp/src/recursive-tokenizer.js"],"sourcesContent":["//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-nlp”.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-underscore-dangle */\n\n// Used in accessing the regex and its category from `rgxs`.\nconst RGX = 0;\nconst CAT = 1;\n// SPECIAL REGULAR EXPRESSIONS:\n// Regex to handle short forms or abbreviations.\nvar rgxShortFormDot = /^(?:(?:[A-Z])(?:\\.))+$/i;\nvar rgxShortForm = /^(?:(?:[A-Z])(?:\\.))+[a-z]?$/i;\n// Regex process hyphenated words.\nvar rgxHyphens = /[\\-\\–\\—]/gi;\nvar rgxPeriod = /[\\.]/gi;\nvar rgxNumber = /[0-9]/;\n\n// ### tokenizer\n/**\n *\n * Creates an instance of `tokenizer`.\n *\n * @param {object} categories token categories, as obtained via the language model.\n * @param {object} preserve rules for hyphenation preservation.\n * @return {function} for recursive tokenization.\n * @private\n*/\nvar tokenizer = function ( categories, preserve ) {\n  // Function to add tokens to the `doc()`.\n  var addToken;\n  var addTokenIfInCache;\n  // Function to test if lexeme exists via `doc()`.\n  var isLexeme;\n  // Preceding Spaces — special need for recursive tokenizer.\n  var ps = 0;\n  // Will only be needed for the first token, after that it si all zero (ps)!\n  var nonBreakingSpaces = null;\n\n  // ### pushHyphenatedToken\n  /**\n   *\n   * Pushes the incoming `tkn` after handling hyphens, if any:\n   * 1. Use it as-is if it is a valid lexeme or contains a number.\n   * 2. Use it as-is if does not contain hyphens.\n   * 3. Otherwise apply rules.\n   *\n   * @param {string} tkn to be processed as per rules hyphenation rules in `preserve`.\n   * @param {array} tokens into which the (split) `tkn` is pushed.\n   * @returns {void} nothing!\n   * @private\n  */\n  var pushHyphenatedToken = function ( tkn, tokens ) {\n    // Will contain pure alpha words, obtained by splitting on `rgxHyphens`.\n    var words;\n    // Will contain mathed hyphens.\n    var hyphens;\n    // Helper variables.\n    var i, k, last;\n\n    // If a token is a valid lexeme or contains one or more number, dont touch it.\n    if ( isLexeme( tkn) || rgxNumber.test( tkn ) ) {\n      tokens.push( [ tkn, categories.word ] );\n      return;\n    }\n\n    hyphens = tkn.match( rgxHyphens );\n    // If there are no hyphens in the word, dont touch it.\n    if ( hyphens === null ) {\n      tokens.push( [ tkn, categories.word ] );\n      return;\n    }\n\n    // Word is hyphenated, process it according to the rules specified in `preserve`.\n    words = tkn.split( rgxHyphens );\n    last = words.length - 1;\n    if ( preserve.prefix[ words[ 0 ] ] || preserve.suffix[ words[ last ] ] ) {\n      tokens.push( [ tkn, categories.word ] );\n      return;\n    }\n    k = 0;\n    for ( i = 0; i < words.length; i += 1 ) {\n      // Do not push any empty token!\n      if ( words[ i ] !== '' ) {\n        tokens.push( [ words[ i ], categories.word ] );\n      }\n\n      if ( k < hyphens.length ) {\n        tokens.push( [ hyphens[ k ], categories.punctuation ] );\n      }\n      k += 1;\n    }\n  }; // pushHyphenatedToken()\n\n  // ### pushWordToken\n  /**\n   *\n   * Pushes the incoming `tkn` after handling periods and hyphens present:\n   * 1. Use it as-is if it is a valid lexeme or a short form ending with a period.\n   * 2. Split on period and the successively assemble tokens using matches & splits.\n   * 3. Finally send each such assembled token down for handling hyphenated word.\n   *\n   * @param {string} tkn to be processed and pushed.\n   * @param {array} tokens into which the (split) `tkn` is pushed.\n   * @returns {void} nothing!\n   * @private\n  */\n  var pushWordToken = function ( tkn, tokens ) {\n    // Will contain words, obtained by splitting on `rgxPeriod`.\n    var words;\n    // Will contain matched periods.\n    var periods;\n    // Helper variables:<br/>\n    // Index variables\n    var i, k;\n    // Used in successively assembling a potential token from matches & words\n    // (i.e. splits), if word has periods.\n    var currBuild = '';\n    var nextBuild = '';\n\n\n    // If a token is a **valid lexeme**, or it is **short form ending with a\n    // period** (e.g. dot) then _dont touch it._\n    if ( isLexeme( tkn ) || rgxShortFormDot.test( tkn ) ) {\n      tokens.push( [ tkn, categories.word ] );\n      return;\n    }\n\n    // Start by matching with periods\n    periods = tkn.match( rgxPeriod );\n    // If there are no periods in the word, dont touch it.\n    if ( periods === null ) {\n      pushHyphenatedToken( tkn, tokens );\n      return;\n    }\n\n    // Word has periods, therefore process it:\n    words = tkn.split( rgxPeriod );\n    k = 0;\n\n    for ( i = 0; i < words.length; i += 1 ) {\n      // Build next potential token by joining the current build with the next word.\n      nextBuild = currBuild + words[ i ];\n      // If it is a valid possibility, then continue building it.\n      if ( rgxShortForm.test( nextBuild ) || ( isLexeme( nextBuild ) && nextBuild.length > 2 ) || ( currBuild === '' ) ) {\n        currBuild = nextBuild;\n      } else {\n        // Else send it down to handle hyphenated word.\n        pushHyphenatedToken( currBuild, tokens );\n        // Reset builds.\n        currBuild = words[ i ];\n        nextBuild = '';\n      }\n\n      if ( k < periods.length ) {\n        // In the same manner handle period sign.\n        nextBuild = currBuild + periods[ k ];\n        if ( rgxShortForm.test( nextBuild ) || ( isLexeme( nextBuild ) && nextBuild.length > 2 ) ) {\n          currBuild = nextBuild;\n        } else {\n          pushHyphenatedToken( currBuild, tokens );\n          tokens.push( [ periods[ k ], categories.punctuation ] );\n          currBuild = '';\n          nextBuild = '';\n        }\n      }\n      k += 1;\n    }\n    // Handle the last piece if applicable.\n    if ( currBuild !== '' ) pushHyphenatedToken( currBuild, tokens );\n  }; // pushWordToken()\n\n  // ### tokenizeTextUnit\n  /**\n   *\n   * Attempts to tokenize the input `text` using the `rgxSplit`. The tokenization\n   * is carried out by combining the regex matches and splits in the right sequence.\n   * The matches are the *real tokens*, whereas splits are text units that are\n   * tokenized in later rounds! The real tokens (i.e. matches) are pushed as\n   * `object` and splits as `string`.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} rgxSplit object containing the regex and it's category.\n   * @return {array} of tokens.\n   * @private\n  */\n  var tokenizeTextUnit = function ( text, rgxSplit ) {\n    // Regex matches go here; note each match is a token and has the same tag\n    // as of regex's category.\n    var matches = text.match( rgxSplit[ RGX ] );\n    // Balance is \"what needs to be tokenized\".\n    var balance = text.split( rgxSplit[ RGX ] );\n    // The result, in form of combination of tokens & matches, is captured here.\n    var tokens = [];\n    // The tag;\n    var tag = rgxSplit[ CAT ];\n    // Helper variables.\n    var i,\n        imax,\n        k,\n        t; // Temp token.\n        // tp; // Temp token with a period sign in end.\n\n    // console.log( matches, balance, text, tag, balance[ 1 ] ); // eslint-disable-line no-console\n    // A `null` value means it is equivalent to no matches i.e. an empty array.\n    matches = ( matches ) ? matches : [];\n    // Handle cases where the word is ending with period for **word category**.\n    // Iterate in [ m0 b1 m1 ... ] pattern as `b0` has no value here.\n    // *** COMMENTED out after `pushWordToken()`:\n    // k = 0;\n    // if ( tag === categories.word ) {\n    //   for ( i = 1, imax = balance.length; i < imax; i += 1 ) {\n    //     t = balance[ i ];\n    //     if ( k < matches.length && t[ 0 ] === '.' ) {\n    //       tp = matches[ k ] + '.';\n    //       if ( isLexeme( tp ) || rgxShortForm.test( tp ) ) {\n    //         matches[ k ] = tp;\n    //         balance[ i ] = t.slice( 1 );\n    //       }\n    //     }\n    //     k += 1;\n    //   }\n    // }\n\n    // console.log( matches, balance, text, tag, balance[ 1 ] ); // eslint-disable-line no-console\n    // Combine tokens & matches in the following pattern [ b0 m0 b1 m1 ... ]\n    k = 0;\n    for ( i = 0, imax = balance.length; i < imax; i += 1 ) {\n      t = balance[ i ];\n      t = t.trim();\n      if ( t ) tokens.push( t );\n      if ( k < matches.length ) {\n        if ( tag === categories.word ) {\n          // Handle special cases for words via:\n          pushWordToken( matches[ k ], tokens );\n        } else {\n          tokens.push( [ matches[ k ], tag ] );\n        }\n      }\n      k += 1;\n    }\n\n    return ( tokens );\n  }; // tokenizeTextUnit()\n\n  // ### tokenizeTextRecursively\n  /**\n   *\n   * Tokenizes the input text recursively using the array of `regexes` and then\n   * the `tokenizeTextUnit()` function. If (or whenever) the `regexes` becomes\n   * empty, it simply splits the text on non-word characters instead of using\n   * the `tokenizeTextUnit()` function.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} regexes object containing the regex and it's category.\n   * @return {undefined} nothing!\n   * @private\n  */\n  var tokenizeTextRecursively = function ( text, regexes ) {\n    var sentence = text.trim();\n    var tokens = [];\n    // Helpers – for loop variables & token category.\n    var i, imax;\n    var cat;\n\n    if ( !regexes.length ) {\n      // No regex left, this is the true **unk**.\n      // Becuase it is `UNK`, we can use `addToken` instead of attempting\n      // `addTokenIfInCache`.\n      addToken( text, categories.unk, ps, nonBreakingSpaces );\n      ps = 0;\n      return;\n    }\n\n    var rgx = regexes[ 0 ];\n    tokens = tokenizeTextUnit( sentence, rgx );\n\n    for ( i = 0, imax = tokens.length; i < imax; i += 1 ) {\n      if ( typeof tokens[ i ] === 'string' ) {\n        // Strings become candidates for further tokenization.\n        tokenizeTextRecursively( tokens[ i ], regexes.slice( 1 ) );\n      } else {\n        // Use the passed value of preceding spaces only once!\n        // First try cache, otherwise make a direct addition. This ensures\n        // processing of expansions.\n        cat = addTokenIfInCache( tokens[ i ][ 0 ], ps, nonBreakingSpaces );\n        if ( cat === categories.unk ) addToken( tokens[ i ][ 0 ], tokens[ i ][ 1 ], ps, nonBreakingSpaces );\n        // Reset `ps` to **0** as there can never be spaces in a text passed to\n        // this tokenizer.\n        ps = 0;\n      }\n    }\n  }; // tokenizeTextRecursively()\n\n  // ### tokenize\n  /**\n   *\n   * Tokenizes the input `sentence` using the function `tokenizeTextRecursively()`.\n   * This acts as the fall back tokenizer to the **linear tokenizer**.\n   *\n   * @method Tokenizer#tokenize\n   * @param {RegExp} rgxs containg regexes for parsing.\n   * @param {string} text the input sentence.\n   * @param {number} precedingSpaces to the text\n   * @param {object} doc contains the document; used here for adding tokens.\n   * @param {array}  nbsp contains non breaking spaces details.\n   * @return {void} nothing!\n   * `value` and its `tag` identifying the type of the token.\n   * @private\n  */\n  var tokenize = function ( rgxs, text, precedingSpaces, doc, nbsp ) {\n    // Cache frequently used doc methods.\n    addToken = doc._addToken;\n    addTokenIfInCache = doc._addTokenIfInCache;\n    isLexeme = doc.isLexeme;\n    // Set `ps` to the passed value of preceding spaces, it will be reset to **0**\n    // after first use during recursion.\n    ps = precedingSpaces;\n    nonBreakingSpaces = nbsp;\n    tokenizeTextRecursively( text, rgxs, precedingSpaces );\n  }; // tokenize()\n\n  return tokenize;\n};\n\nmodule.exports = tokenizer;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA,MAAMA,GAAG,GAAG,CAAC;AACb,MAAMC,GAAG,GAAG,CAAC;AACb;AACA;AACA,IAAIC,eAAe,GAAG,yBAAyB;AAC/C,IAAIC,YAAY,GAAG,+BAA+B;AAClD;AACA,IAAIC,UAAU,GAAG,YAAY;AAC7B,IAAIC,SAAS,GAAG,QAAQ;AACxB,IAAIC,SAAS,GAAG,OAAO;;AAEvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAIC,SAAS,GAAG,SAAAA,CAAWC,UAAU,EAAEC,QAAQ,EAAG;EAChD;EACA,IAAIC,QAAQ;EACZ,IAAIC,iBAAiB;EACrB;EACA,IAAIC,QAAQ;EACZ;EACA,IAAIC,EAAE,GAAG,CAAC;EACV;EACA,IAAIC,iBAAiB,GAAG,IAAI;;EAE5B;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIC,mBAAmB,GAAG,SAAAA,CAAWC,GAAG,EAAEC,MAAM,EAAG;IACjD;IACA,IAAIC,KAAK;IACT;IACA,IAAIC,OAAO;IACX;IACA,IAAIC,CAAC,EAAEC,CAAC,EAAEC,IAAI;;IAEd;IACA,IAAKV,QAAQ,CAAEI,GAAG,CAAC,IAAIV,SAAS,CAACiB,IAAI,CAAEP,GAAI,CAAC,EAAG;MAC7CC,MAAM,CAACO,IAAI,CAAE,CAAER,GAAG,EAAER,UAAU,CAACiB,IAAI,CAAG,CAAC;MACvC;IACF;IAEAN,OAAO,GAAGH,GAAG,CAACU,KAAK,CAAEtB,UAAW,CAAC;IACjC;IACA,IAAKe,OAAO,KAAK,IAAI,EAAG;MACtBF,MAAM,CAACO,IAAI,CAAE,CAAER,GAAG,EAAER,UAAU,CAACiB,IAAI,CAAG,CAAC;MACvC;IACF;;IAEA;IACAP,KAAK,GAAGF,GAAG,CAACW,KAAK,CAAEvB,UAAW,CAAC;IAC/BkB,IAAI,GAAGJ,KAAK,CAACU,MAAM,GAAG,CAAC;IACvB,IAAKnB,QAAQ,CAACoB,MAAM,CAAEX,KAAK,CAAE,CAAC,CAAE,CAAE,IAAIT,QAAQ,CAACqB,MAAM,CAAEZ,KAAK,CAAEI,IAAI,CAAE,CAAE,EAAG;MACvEL,MAAM,CAACO,IAAI,CAAE,CAAER,GAAG,EAAER,UAAU,CAACiB,IAAI,CAAG,CAAC;MACvC;IACF;IACAJ,CAAC,GAAG,CAAC;IACL,KAAMD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,KAAK,CAACU,MAAM,EAAER,CAAC,IAAI,CAAC,EAAG;MACtC;MACA,IAAKF,KAAK,CAAEE,CAAC,CAAE,KAAK,EAAE,EAAG;QACvBH,MAAM,CAACO,IAAI,CAAE,CAAEN,KAAK,CAAEE,CAAC,CAAE,EAAEZ,UAAU,CAACiB,IAAI,CAAG,CAAC;MAChD;MAEA,IAAKJ,CAAC,GAAGF,OAAO,CAACS,MAAM,EAAG;QACxBX,MAAM,CAACO,IAAI,CAAE,CAAEL,OAAO,CAAEE,CAAC,CAAE,EAAEb,UAAU,CAACuB,WAAW,CAAG,CAAC;MACzD;MACAV,CAAC,IAAI,CAAC;IACR;EACF,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIW,aAAa,GAAG,SAAAA,CAAWhB,GAAG,EAAEC,MAAM,EAAG;IAC3C;IACA,IAAIC,KAAK;IACT;IACA,IAAIe,OAAO;IACX;IACA;IACA,IAAIb,CAAC,EAAEC,CAAC;IACR;IACA;IACA,IAAIa,SAAS,GAAG,EAAE;IAClB,IAAIC,SAAS,GAAG,EAAE;;IAGlB;IACA;IACA,IAAKvB,QAAQ,CAAEI,GAAI,CAAC,IAAId,eAAe,CAACqB,IAAI,CAAEP,GAAI,CAAC,EAAG;MACpDC,MAAM,CAACO,IAAI,CAAE,CAAER,GAAG,EAAER,UAAU,CAACiB,IAAI,CAAG,CAAC;MACvC;IACF;;IAEA;IACAQ,OAAO,GAAGjB,GAAG,CAACU,KAAK,CAAErB,SAAU,CAAC;IAChC;IACA,IAAK4B,OAAO,KAAK,IAAI,EAAG;MACtBlB,mBAAmB,CAAEC,GAAG,EAAEC,MAAO,CAAC;MAClC;IACF;;IAEA;IACAC,KAAK,GAAGF,GAAG,CAACW,KAAK,CAAEtB,SAAU,CAAC;IAC9BgB,CAAC,GAAG,CAAC;IAEL,KAAMD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,KAAK,CAACU,MAAM,EAAER,CAAC,IAAI,CAAC,EAAG;MACtC;MACAe,SAAS,GAAGD,SAAS,GAAGhB,KAAK,CAAEE,CAAC,CAAE;MAClC;MACA,IAAKjB,YAAY,CAACoB,IAAI,CAAEY,SAAU,CAAC,IAAMvB,QAAQ,CAAEuB,SAAU,CAAC,IAAIA,SAAS,CAACP,MAAM,GAAG,CAAG,IAAMM,SAAS,KAAK,EAAI,EAAG;QACjHA,SAAS,GAAGC,SAAS;MACvB,CAAC,MAAM;QACL;QACApB,mBAAmB,CAAEmB,SAAS,EAAEjB,MAAO,CAAC;QACxC;QACAiB,SAAS,GAAGhB,KAAK,CAAEE,CAAC,CAAE;QACtBe,SAAS,GAAG,EAAE;MAChB;MAEA,IAAKd,CAAC,GAAGY,OAAO,CAACL,MAAM,EAAG;QACxB;QACAO,SAAS,GAAGD,SAAS,GAAGD,OAAO,CAAEZ,CAAC,CAAE;QACpC,IAAKlB,YAAY,CAACoB,IAAI,CAAEY,SAAU,CAAC,IAAMvB,QAAQ,CAAEuB,SAAU,CAAC,IAAIA,SAAS,CAACP,MAAM,GAAG,CAAG,EAAG;UACzFM,SAAS,GAAGC,SAAS;QACvB,CAAC,MAAM;UACLpB,mBAAmB,CAAEmB,SAAS,EAAEjB,MAAO,CAAC;UACxCA,MAAM,CAACO,IAAI,CAAE,CAAES,OAAO,CAAEZ,CAAC,CAAE,EAAEb,UAAU,CAACuB,WAAW,CAAG,CAAC;UACvDG,SAAS,GAAG,EAAE;UACdC,SAAS,GAAG,EAAE;QAChB;MACF;MACAd,CAAC,IAAI,CAAC;IACR;IACA;IACA,IAAKa,SAAS,KAAK,EAAE,EAAGnB,mBAAmB,CAAEmB,SAAS,EAAEjB,MAAO,CAAC;EAClE,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAImB,gBAAgB,GAAG,SAAAA,CAAWC,IAAI,EAAEC,QAAQ,EAAG;IACjD;IACA;IACA,IAAIC,OAAO,GAAGF,IAAI,CAACX,KAAK,CAAEY,QAAQ,CAAEtC,GAAG,CAAG,CAAC;IAC3C;IACA,IAAIwC,OAAO,GAAGH,IAAI,CAACV,KAAK,CAAEW,QAAQ,CAAEtC,GAAG,CAAG,CAAC;IAC3C;IACA,IAAIiB,MAAM,GAAG,EAAE;IACf;IACA,IAAIwB,GAAG,GAAGH,QAAQ,CAAErC,GAAG,CAAE;IACzB;IACA,IAAImB,CAAC,EACDsB,IAAI,EACJrB,CAAC,EACDsB,CAAC,CAAC,CAAC;IACH;;IAEJ;IACA;IACAJ,OAAO,GAAKA,OAAO,GAAKA,OAAO,GAAG,EAAE;IACpC;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;;IAEA;IACA;IACAlB,CAAC,GAAG,CAAC;IACL,KAAMD,CAAC,GAAG,CAAC,EAAEsB,IAAI,GAAGF,OAAO,CAACZ,MAAM,EAAER,CAAC,GAAGsB,IAAI,EAAEtB,CAAC,IAAI,CAAC,EAAG;MACrDuB,CAAC,GAAGH,OAAO,CAAEpB,CAAC,CAAE;MAChBuB,CAAC,GAAGA,CAAC,CAACC,IAAI,CAAC,CAAC;MACZ,IAAKD,CAAC,EAAG1B,MAAM,CAACO,IAAI,CAAEmB,CAAE,CAAC;MACzB,IAAKtB,CAAC,GAAGkB,OAAO,CAACX,MAAM,EAAG;QACxB,IAAKa,GAAG,KAAKjC,UAAU,CAACiB,IAAI,EAAG;UAC7B;UACAO,aAAa,CAAEO,OAAO,CAAElB,CAAC,CAAE,EAAEJ,MAAO,CAAC;QACvC,CAAC,MAAM;UACLA,MAAM,CAACO,IAAI,CAAE,CAAEe,OAAO,CAAElB,CAAC,CAAE,EAAEoB,GAAG,CAAG,CAAC;QACtC;MACF;MACApB,CAAC,IAAI,CAAC;IACR;IAEA,OAASJ,MAAM;EACjB,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAI4B,uBAAuB,GAAG,SAAAA,CAAWR,IAAI,EAAES,OAAO,EAAG;IACvD,IAAIC,QAAQ,GAAGV,IAAI,CAACO,IAAI,CAAC,CAAC;IAC1B,IAAI3B,MAAM,GAAG,EAAE;IACf;IACA,IAAIG,CAAC,EAAEsB,IAAI;IACX,IAAIM,GAAG;IAEP,IAAK,CAACF,OAAO,CAAClB,MAAM,EAAG;MACrB;MACA;MACA;MACAlB,QAAQ,CAAE2B,IAAI,EAAE7B,UAAU,CAACyC,GAAG,EAAEpC,EAAE,EAAEC,iBAAkB,CAAC;MACvDD,EAAE,GAAG,CAAC;MACN;IACF;IAEA,IAAIqC,GAAG,GAAGJ,OAAO,CAAE,CAAC,CAAE;IACtB7B,MAAM,GAAGmB,gBAAgB,CAAEW,QAAQ,EAAEG,GAAI,CAAC;IAE1C,KAAM9B,CAAC,GAAG,CAAC,EAAEsB,IAAI,GAAGzB,MAAM,CAACW,MAAM,EAAER,CAAC,GAAGsB,IAAI,EAAEtB,CAAC,IAAI,CAAC,EAAG;MACpD,IAAK,OAAOH,MAAM,CAAEG,CAAC,CAAE,KAAK,QAAQ,EAAG;QACrC;QACAyB,uBAAuB,CAAE5B,MAAM,CAAEG,CAAC,CAAE,EAAE0B,OAAO,CAACK,KAAK,CAAE,CAAE,CAAE,CAAC;MAC5D,CAAC,MAAM;QACL;QACA;QACA;QACAH,GAAG,GAAGrC,iBAAiB,CAAEM,MAAM,CAAEG,CAAC,CAAE,CAAE,CAAC,CAAE,EAAEP,EAAE,EAAEC,iBAAkB,CAAC;QAClE,IAAKkC,GAAG,KAAKxC,UAAU,CAACyC,GAAG,EAAGvC,QAAQ,CAAEO,MAAM,CAAEG,CAAC,CAAE,CAAE,CAAC,CAAE,EAAEH,MAAM,CAAEG,CAAC,CAAE,CAAE,CAAC,CAAE,EAAEP,EAAE,EAAEC,iBAAkB,CAAC;QACnG;QACA;QACAD,EAAE,GAAG,CAAC;MACR;IACF;EACF,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIuC,QAAQ,GAAG,SAAAA,CAAWC,IAAI,EAAEhB,IAAI,EAAEiB,eAAe,EAAEC,GAAG,EAAEC,IAAI,EAAG;IACjE;IACA9C,QAAQ,GAAG6C,GAAG,CAACE,SAAS;IACxB9C,iBAAiB,GAAG4C,GAAG,CAACG,kBAAkB;IAC1C9C,QAAQ,GAAG2C,GAAG,CAAC3C,QAAQ;IACvB;IACA;IACAC,EAAE,GAAGyC,eAAe;IACpBxC,iBAAiB,GAAG0C,IAAI;IACxBX,uBAAuB,CAAER,IAAI,EAAEgB,IAAI,EAAEC,eAAgB,CAAC;EACxD,CAAC,CAAC,CAAC;;EAEH,OAAOF,QAAQ;AACjB,CAAC;AAEDO,MAAM,CAACC,OAAO,GAAGrD,SAAS","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}