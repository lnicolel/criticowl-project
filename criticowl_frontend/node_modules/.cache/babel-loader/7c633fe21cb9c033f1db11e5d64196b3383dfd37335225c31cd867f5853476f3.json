{"ast":null,"code":"//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-nlp”.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-underscore-dangle */\n\nvar constants = require('./constants.js');\n\n// Bits reserved for `precedingSpaces`.\nvar bits4PrecedingSpace = constants.bits4PrecedingSpace;\n// Size of a single expansion.\nvar xpSize = constants.xpSize;\n// Bits reserved for `lemma`.\nvar bits4lemma = constants.bits4lemma;\n// The UNK!\nvar UNK = constants.UNK;\n// Size of a single token.\nvar tkSize = constants.tkSize;\nvar docDataWrapper = function (data) {\n  // Extract frequently referred data elements:\n  // Extract `cache`.\n  var cache = data.cache;\n  // Extract `tokens`.\n  var tokens = data.tokens;\n\n  // Returned!\n  var methods = Object.create(null);\n\n  // ## addToken\n  /**\n   *\n   * It first creates a new lexeme entry into the `cache` and then this entry\n   * is pushed into the `tokens` array alongwith the `precedingSpaces` and\n   * rest of the token properties are initialized to `0`.\n   *\n   * @param {string} text to be added as token.\n   * @param {string} category of the token.\n   * @param {number} precedingSpaces to the `text` as parsed by tokenizer.\n   * @param {array} nbsp, containing details of nbsp.\n   * @returns {boolean} always `true`.\n   * @private\n  */\n  var addToken = function (text, category, precedingSpaces, nbsp) {\n    // Non-normalized index of the token being pushed.\n    var idx;\n    idx = tokens.push(cache.add(text, category), precedingSpaces, 0, 0);\n    // See comments in `addTokenIfInCache()`\n    if (nbsp !== null && precedingSpaces > 0) data.nonBreakingSpaces[idx / tkSize - 1] = nbsp;\n    return true;\n  }; // addToken()\n\n  // ## addTokenIfInCache\n  /**\n   *\n   * Adds a token corresponding to the input `text` if it is found in cache i.e.\n   * not an OOV. The addition process ensures the following:\n   * 1. Preceding spaces are added.\n   * 2. If text is a contraction, it expansions are added. Since expansins\n   * consists of lexeme, normal, lemma and pos, all of these are added to the\n   * token structure.\n   *\n   * @param {string} text to be added as token.\n   * @param {number} precedingSpaces to the `text` as parsed by tokenizer.\n   * @param {string} nbsp non breaking spaces\n   * @returns {boolean} `truthy` if `text` is found in cache otherwise `falsy`.\n   * @private\n  */\n  var addTokenIfInCache = function (text, precedingSpaces, nbsp) {\n    // The array `tokenIndex` will contain 1-element if `text` is not a predefined\n    // contraction; otherwise it will contain `n x 4` elements, where `n` is the\n    // number of expansions.\n    var tokenIndex = cache.lookup(text);\n    // Temp for preceding space in case of contarction.\n    var ps;\n    // Temp for lemma & pos.\n    var lemma, pos;\n    // Non-normalized index of the token being pushed.\n    var idx;\n\n    // `UNK` means 0 or `falsy`; it flags that token has not been added.\n    if (tokenIndex === null) return UNK;\n    if (tokenIndex.length === 1) {\n      idx = tokens.push(tokenIndex[0], precedingSpaces, 0, 0);\n      // Store non breaking spaces preceding this token. Do it only if `precedingSpaces > 0` (Note:\n      // it is zero in case of expansion of a contraction) AND `nbsp` is defined (Note: in this case\n      // precedingSpaces would be set to max i.e. 0xFFFF with only exception when the token is being\n      // expanded: the first one will have nbsp but the subsequent ones with have 0 preceding spaces).\n      // The storage index should be the normalaized token index.\n      if (nbsp !== null && precedingSpaces > 0) data.nonBreakingSpaces[idx / tkSize - 1] = nbsp;\n    } else {\n      // Contraction, itereate through each expansion.\n      for (let k = 0; k < tokenIndex.length; k += xpSize) {\n        // The `precedingSpaces` will be 0 except for the first expansion.\n        ps = k === 0 ? precedingSpaces : 0;\n        // Concatenate pointer to normal contained in `xpansions` with preceding\n        // spaces.\n        ps |= tokenIndex[k + 1] << bits4PrecedingSpace; // eslint-disable-line no-bitwise\n        // Lemma & POS are fixed mostly for all contractions.\n        lemma = tokenIndex[k + 2];\n        pos = tokenIndex[k + 3];\n        // Add token; annotations may be filled later in the pipeline.\n        idx = tokens.push(tokenIndex[k], ps, lemma | pos << bits4lemma, 0); // eslint-disable-line no-bitwise\n        // See comment above in the then block of this if-statement.\n        if (nbsp !== null && precedingSpaces > 0) data.nonBreakingSpaces[idx / tkSize - 1] = nbsp;\n      }\n    }\n    // Return `truthy`, indicating that token(s) has been added successfully.\n    return 99;\n  }; // addTokenIfInCache()\n\n  // ## isLexeme\n  /**\n   *\n   * Tests if the `text` is a valid lexeme or not.\n   *\n   * @param {string} text to be added as token.\n   * @returns {boolean} `truthy` if `text` is a valid lexeme otherwise `falsy`.\n   * @private\n  */\n  var isLexeme = function (text) {\n    // Return `truthy` if the text is valid i.e. found. Note for `$%^OOV^%$`, it returns\n    // `0` i.e. `falsy`!\n    return cache.lookup(text);\n  }; // isLexeme()\n\n  var clean = function () {\n    tokens = null;\n    cache = null;\n  }; // clean()\n\n  methods._addToken = addToken;\n  methods._addTokenIfInCache = addTokenIfInCache;\n  methods.isLexeme = isLexeme;\n  methods.clean = clean;\n  return methods;\n}; // docDataWrapper()\n\nmodule.exports = docDataWrapper;","map":{"version":3,"names":["constants","require","bits4PrecedingSpace","xpSize","bits4lemma","UNK","tkSize","docDataWrapper","data","cache","tokens","methods","Object","create","addToken","text","category","precedingSpaces","nbsp","idx","push","add","nonBreakingSpaces","addTokenIfInCache","tokenIndex","lookup","ps","lemma","pos","length","k","isLexeme","clean","_addToken","_addTokenIfInCache","module","exports"],"sources":["C:/Users/cheko/Desktop/Education/Freelance/criticowl-main/criticowl_frontend/node_modules/wink-nlp/src/dd-wrapper.js"],"sourcesContent":["//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of “wink-nlp”.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-underscore-dangle */\n\nvar constants = require( './constants.js' );\n\n// Bits reserved for `precedingSpaces`.\nvar bits4PrecedingSpace = constants.bits4PrecedingSpace;\n// Size of a single expansion.\nvar xpSize = constants.xpSize;\n// Bits reserved for `lemma`.\nvar bits4lemma = constants.bits4lemma;\n// The UNK!\nvar UNK = constants.UNK;\n// Size of a single token.\nvar tkSize = constants.tkSize;\n\nvar docDataWrapper = function ( data ) {\n  // Extract frequently referred data elements:\n  // Extract `cache`.\n  var cache = data.cache;\n  // Extract `tokens`.\n  var tokens = data.tokens;\n\n  // Returned!\n  var methods = Object.create( null );\n\n  // ## addToken\n  /**\n   *\n   * It first creates a new lexeme entry into the `cache` and then this entry\n   * is pushed into the `tokens` array alongwith the `precedingSpaces` and\n   * rest of the token properties are initialized to `0`.\n   *\n   * @param {string} text to be added as token.\n   * @param {string} category of the token.\n   * @param {number} precedingSpaces to the `text` as parsed by tokenizer.\n   * @param {array} nbsp, containing details of nbsp.\n   * @returns {boolean} always `true`.\n   * @private\n  */\n  var addToken = function ( text, category, precedingSpaces, nbsp ) {\n    // Non-normalized index of the token being pushed.\n    var idx;\n    idx = tokens.push( cache.add( text, category ), precedingSpaces, 0, 0 );\n    // See comments in `addTokenIfInCache()`\n    if ( nbsp !== null && precedingSpaces > 0 ) data.nonBreakingSpaces[ ( idx / tkSize ) - 1 ] = nbsp;\n    return true;\n  }; // addToken()\n\n  // ## addTokenIfInCache\n  /**\n   *\n   * Adds a token corresponding to the input `text` if it is found in cache i.e.\n   * not an OOV. The addition process ensures the following:\n   * 1. Preceding spaces are added.\n   * 2. If text is a contraction, it expansions are added. Since expansins\n   * consists of lexeme, normal, lemma and pos, all of these are added to the\n   * token structure.\n   *\n   * @param {string} text to be added as token.\n   * @param {number} precedingSpaces to the `text` as parsed by tokenizer.\n   * @param {string} nbsp non breaking spaces\n   * @returns {boolean} `truthy` if `text` is found in cache otherwise `falsy`.\n   * @private\n  */\n  var addTokenIfInCache = function ( text, precedingSpaces, nbsp ) {\n    // The array `tokenIndex` will contain 1-element if `text` is not a predefined\n    // contraction; otherwise it will contain `n x 4` elements, where `n` is the\n    // number of expansions.\n    var tokenIndex = cache.lookup( text );\n    // Temp for preceding space in case of contarction.\n    var ps;\n    // Temp for lemma & pos.\n    var lemma, pos;\n    // Non-normalized index of the token being pushed.\n    var idx;\n\n    // `UNK` means 0 or `falsy`; it flags that token has not been added.\n    if ( tokenIndex === null ) return UNK;\n\n    if ( tokenIndex.length === 1 ) {\n      idx = tokens.push( tokenIndex[ 0 ], precedingSpaces, 0, 0 );\n      // Store non breaking spaces preceding this token. Do it only if `precedingSpaces > 0` (Note:\n      // it is zero in case of expansion of a contraction) AND `nbsp` is defined (Note: in this case\n      // precedingSpaces would be set to max i.e. 0xFFFF with only exception when the token is being\n      // expanded: the first one will have nbsp but the subsequent ones with have 0 preceding spaces).\n      // The storage index should be the normalaized token index.\n      if ( nbsp !== null && precedingSpaces > 0 ) data.nonBreakingSpaces[ ( idx / tkSize ) - 1 ] = nbsp;\n    } else {\n      // Contraction, itereate through each expansion.\n      for ( let k = 0; k < tokenIndex.length; k += xpSize ) {\n        // The `precedingSpaces` will be 0 except for the first expansion.\n        ps = ( k === 0 ) ? precedingSpaces : 0;\n        // Concatenate pointer to normal contained in `xpansions` with preceding\n        // spaces.\n        ps |= ( tokenIndex[ k + 1 ] << bits4PrecedingSpace ); // eslint-disable-line no-bitwise\n        // Lemma & POS are fixed mostly for all contractions.\n        lemma = tokenIndex[ k + 2 ];\n        pos   = tokenIndex[ k + 3 ];\n        // Add token; annotations may be filled later in the pipeline.\n        idx = tokens.push( tokenIndex[ k ], ps, ( lemma | ( pos << bits4lemma ) ), 0 ); // eslint-disable-line no-bitwise\n        // See comment above in the then block of this if-statement.\n        if ( nbsp !== null && precedingSpaces > 0 ) data.nonBreakingSpaces[ ( idx / tkSize ) - 1 ] = nbsp;\n      }\n    }\n    // Return `truthy`, indicating that token(s) has been added successfully.\n    return 99;\n  }; // addTokenIfInCache()\n\n  // ## isLexeme\n  /**\n   *\n   * Tests if the `text` is a valid lexeme or not.\n   *\n   * @param {string} text to be added as token.\n   * @returns {boolean} `truthy` if `text` is a valid lexeme otherwise `falsy`.\n   * @private\n  */\n  var isLexeme = function ( text ) {\n    // Return `truthy` if the text is valid i.e. found. Note for `$%^OOV^%$`, it returns\n    // `0` i.e. `falsy`!\n    return cache.lookup( text );\n  }; // isLexeme()\n\n  var clean = function () {\n    tokens = null;\n    cache = null;\n  }; // clean()\n\n  methods._addToken = addToken;\n  methods._addTokenIfInCache = addTokenIfInCache;\n  methods.isLexeme = isLexeme;\n  methods.clean = clean;\n\n  return methods;\n}; // docDataWrapper()\n\nmodule.exports = docDataWrapper;\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA,IAAIA,SAAS,GAAGC,OAAO,CAAE,gBAAiB,CAAC;;AAE3C;AACA,IAAIC,mBAAmB,GAAGF,SAAS,CAACE,mBAAmB;AACvD;AACA,IAAIC,MAAM,GAAGH,SAAS,CAACG,MAAM;AAC7B;AACA,IAAIC,UAAU,GAAGJ,SAAS,CAACI,UAAU;AACrC;AACA,IAAIC,GAAG,GAAGL,SAAS,CAACK,GAAG;AACvB;AACA,IAAIC,MAAM,GAAGN,SAAS,CAACM,MAAM;AAE7B,IAAIC,cAAc,GAAG,SAAAA,CAAWC,IAAI,EAAG;EACrC;EACA;EACA,IAAIC,KAAK,GAAGD,IAAI,CAACC,KAAK;EACtB;EACA,IAAIC,MAAM,GAAGF,IAAI,CAACE,MAAM;;EAExB;EACA,IAAIC,OAAO,GAAGC,MAAM,CAACC,MAAM,CAAE,IAAK,CAAC;;EAEnC;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIC,QAAQ,GAAG,SAAAA,CAAWC,IAAI,EAAEC,QAAQ,EAAEC,eAAe,EAAEC,IAAI,EAAG;IAChE;IACA,IAAIC,GAAG;IACPA,GAAG,GAAGT,MAAM,CAACU,IAAI,CAAEX,KAAK,CAACY,GAAG,CAAEN,IAAI,EAAEC,QAAS,CAAC,EAAEC,eAAe,EAAE,CAAC,EAAE,CAAE,CAAC;IACvE;IACA,IAAKC,IAAI,KAAK,IAAI,IAAID,eAAe,GAAG,CAAC,EAAGT,IAAI,CAACc,iBAAiB,CAAIH,GAAG,GAAGb,MAAM,GAAK,CAAC,CAAE,GAAGY,IAAI;IACjG,OAAO,IAAI;EACb,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIK,iBAAiB,GAAG,SAAAA,CAAWR,IAAI,EAAEE,eAAe,EAAEC,IAAI,EAAG;IAC/D;IACA;IACA;IACA,IAAIM,UAAU,GAAGf,KAAK,CAACgB,MAAM,CAAEV,IAAK,CAAC;IACrC;IACA,IAAIW,EAAE;IACN;IACA,IAAIC,KAAK,EAAEC,GAAG;IACd;IACA,IAAIT,GAAG;;IAEP;IACA,IAAKK,UAAU,KAAK,IAAI,EAAG,OAAOnB,GAAG;IAErC,IAAKmB,UAAU,CAACK,MAAM,KAAK,CAAC,EAAG;MAC7BV,GAAG,GAAGT,MAAM,CAACU,IAAI,CAAEI,UAAU,CAAE,CAAC,CAAE,EAAEP,eAAe,EAAE,CAAC,EAAE,CAAE,CAAC;MAC3D;MACA;MACA;MACA;MACA;MACA,IAAKC,IAAI,KAAK,IAAI,IAAID,eAAe,GAAG,CAAC,EAAGT,IAAI,CAACc,iBAAiB,CAAIH,GAAG,GAAGb,MAAM,GAAK,CAAC,CAAE,GAAGY,IAAI;IACnG,CAAC,MAAM;MACL;MACA,KAAM,IAAIY,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGN,UAAU,CAACK,MAAM,EAAEC,CAAC,IAAI3B,MAAM,EAAG;QACpD;QACAuB,EAAE,GAAKI,CAAC,KAAK,CAAC,GAAKb,eAAe,GAAG,CAAC;QACtC;QACA;QACAS,EAAE,IAAMF,UAAU,CAAEM,CAAC,GAAG,CAAC,CAAE,IAAI5B,mBAAqB,CAAC,CAAC;QACtD;QACAyB,KAAK,GAAGH,UAAU,CAAEM,CAAC,GAAG,CAAC,CAAE;QAC3BF,GAAG,GAAKJ,UAAU,CAAEM,CAAC,GAAG,CAAC,CAAE;QAC3B;QACAX,GAAG,GAAGT,MAAM,CAACU,IAAI,CAAEI,UAAU,CAAEM,CAAC,CAAE,EAAEJ,EAAE,EAAIC,KAAK,GAAKC,GAAG,IAAIxB,UAAY,EAAI,CAAE,CAAC,CAAC,CAAC;QAChF;QACA,IAAKc,IAAI,KAAK,IAAI,IAAID,eAAe,GAAG,CAAC,EAAGT,IAAI,CAACc,iBAAiB,CAAIH,GAAG,GAAGb,MAAM,GAAK,CAAC,CAAE,GAAGY,IAAI;MACnG;IACF;IACA;IACA,OAAO,EAAE;EACX,CAAC,CAAC,CAAC;;EAEH;EACA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;EACE,IAAIa,QAAQ,GAAG,SAAAA,CAAWhB,IAAI,EAAG;IAC/B;IACA;IACA,OAAON,KAAK,CAACgB,MAAM,CAAEV,IAAK,CAAC;EAC7B,CAAC,CAAC,CAAC;;EAEH,IAAIiB,KAAK,GAAG,SAAAA,CAAA,EAAY;IACtBtB,MAAM,GAAG,IAAI;IACbD,KAAK,GAAG,IAAI;EACd,CAAC,CAAC,CAAC;;EAEHE,OAAO,CAACsB,SAAS,GAAGnB,QAAQ;EAC5BH,OAAO,CAACuB,kBAAkB,GAAGX,iBAAiB;EAC9CZ,OAAO,CAACoB,QAAQ,GAAGA,QAAQ;EAC3BpB,OAAO,CAACqB,KAAK,GAAGA,KAAK;EAErB,OAAOrB,OAAO;AAChB,CAAC,CAAC,CAAC;;AAEHwB,MAAM,CAACC,OAAO,GAAG7B,cAAc","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}